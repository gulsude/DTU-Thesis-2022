{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "train_done = True\n",
    "study_id = 'original'\n",
    "write_in_file = False\n",
    "\n",
    "data_ = 'TransMut'\n",
    "\n",
    "data_dir = '/home/s202357/thesis/transmut/data/transmut_github/'\n",
    "model_folder = '/home/s202357/thesis/transmut/pipeline/{}/models/'.format(study_id)\n",
    "result_folder = '/home/s202357/thesis/transmut/pipeline/{}/results/'.format(study_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mphoebe                       \u001b[m  Sat Jun 18 22:27:41 2022  \u001b[1m\u001b[30m470.103.01\u001b[m\r\n",
      "\u001b[36m[0]\u001b[m \u001b[34mNVIDIA GeForce GTX 1080 Ti\u001b[m |\u001b[31m 21'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m  791\u001b[m / \u001b[33m11178\u001b[m MB | \u001b[1m\u001b[30ms202357\u001b[m(\u001b[33m787M\u001b[m)\r\n",
      "\u001b[36m[1]\u001b[m \u001b[34mNVIDIA GeForce GTX 1080 Ti\u001b[m |\u001b[31m 22'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    4\u001b[m / \u001b[33m11178\u001b[m MB |\r\n",
      "\u001b[36m[2]\u001b[m \u001b[34mNVIDIA GeForce GTX 1080 Ti\u001b[m |\u001b[31m 23'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    4\u001b[m / \u001b[33m11178\u001b[m MB |\r\n",
      "\u001b[36m[3]\u001b[m \u001b[34mNVIDIA GeForce GTX 1080 Ti\u001b[m |\u001b[31m 22'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    1\u001b[m / \u001b[33m11178\u001b[m MB |\r\n",
      "\u001b[36m[4]\u001b[m \u001b[34mNVIDIA GeForce GTX 1080 Ti\u001b[m |\u001b[31m 22'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    1\u001b[m / \u001b[33m11178\u001b[m MB |\r\n",
      "\u001b[36m[5]\u001b[m \u001b[34mNVIDIA GeForce GTX 1080 Ti\u001b[m |\u001b[31m 23'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    1\u001b[m / \u001b[33m11178\u001b[m MB |\r\n",
      "\u001b[36m[6]\u001b[m \u001b[34mNVIDIA GeForce GTX 1080 Ti\u001b[m |\u001b[31m 22'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    1\u001b[m / \u001b[33m11178\u001b[m MB |\r\n",
      "\u001b[36m[7]\u001b[m \u001b[34mNVIDIA GeForce GTX 1080 Ti\u001b[m |\u001b[31m 20'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    1\u001b[m / \u001b[33m11178\u001b[m MB |\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "random.seed(1234)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "from tqdm import tqdm, trange\n",
    "import seaborn as sn\n",
    "from copy import deepcopy\n",
    "\n",
    "from IPython.display import HTML\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, auc, accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/s202357/thesis/transmut/pipeline/procedure/functions')\n",
    "sys.path.append('/home/s202357/thesis/transmut/pipeline/procedure/architecture')\n",
    "\n",
    "import functions as fnc\n",
    "from model_components import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) avalable.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    use_cuda = True\n",
    "    print('There are %d GPU(s) avalable.' % torch.cuda.device_count())\n",
    "else:\n",
    "    print('No GPUs available. Using CPU instead.')\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seed = 19961231\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = [\n",
    "[ ['05p', 'Blosum_ED', 20], ['1p', 'Blosum_ED', 20], ['25p', 'Blosum_ED', 20],  ['75p', 'Blosum_ED', 20], ['100p', 'Blosum_ED', 20]],\n",
    "[ ['05p', 'EmbeddingAttention', 4], ['1p', 'EmbeddingAttention', 4],   ['25p', 'EmbeddingAttention', 4],  ['75p', 'EmbeddingAttention', 4], ['100p', 'EmbeddingAttention', 4]],\n",
    "[ ['05p', 'EmbeddingAttention', 20], ['1p', 'EmbeddingAttention', 20],  ['25p', 'EmbeddingAttention', 20], ['75p', 'EmbeddingAttention', 20], ['100p', 'EmbeddingAttention', 20]],    \n",
    "[ ['05p', 'EmbeddingAttention', 32], ['1p', 'EmbeddingAttention', 32],  ['25p', 'EmbeddingAttention', 32], ['75p', 'EmbeddingAttention', 32], ['100p', 'EmbeddingAttention', 32]],\n",
    "[ ['05p', 'EmbeddingAttention', 64], ['1p', 'EmbeddingAttention', 64],  ['25p', 'EmbeddingAttention', 64], ['75p', 'EmbeddingAttention', 64], ['100p', 'EmbeddingAttention', 64]]\n",
    "]\n",
    "\n",
    "blosum_dict = {\n",
    "'A' : [5,-2,-1,-2,-1,-1,-1,0,-2,-1,-2,-1,-1,-3,-1,1,0,-3,-2,0],\n",
    "'R' : [-2,7,-1,-2,-4,1,0,-3,0,-4,-3,3,-2,-3,-3,-1,-1,-3,-1,-3],\n",
    "'N' : [-1,-1,7,2,-2,0,0,0,1,-3,-4,0,-2,-4,-2,1,0,-4,-2,-3],\n",
    "'D' : [-2,-2,2,8,-4,0,2,-1,-1,-4,-4,-1,-4,-5,-1,0,-1,-5,-3,-4],\n",
    "'C' : [-1,-4,-2,-4,13,-3,-3,-3,-3,-2,-2,-3,-2,-2,-4,-1,-1,-5,-3,-1],\n",
    "'Q' : [-1,1,0,0,-3,7,2,-2,1,-3,-2,2,0,-4,-1,0,-1,-1,-1,-3],\n",
    "'E' : [-1,0,0,2,-3,2,6,-3,0,-4,-3,1,-2,-3,-1,-1,-1,-3,-2,-3],\n",
    "'G' : [0,-3,0,-1,-3,-2,-3,8,-2,-4,-4,-2,-3,-4,-2,0,-2,-3,-3,-4],\n",
    "'H' : [-2,0,1,-1,-3,1,0,-2,10,-4,-3,0,-1,-1,-2,-1,-2,-3,2,-4],\n",
    "'I' : [-1,-4,-3,-4,-2,-3,-4,-4,-4,5,2,-3,2,0,-3,-3,-1,-3,-1,4],\n",
    "'L' : [-2,-3,-4,-4,-2,-2,-3,-4,-3,2,5,-3,3,1,-4,-3,-1,-2,-1,1],\n",
    "'K' : [-1,3,0,-1,-3,2,1,-2,0,-3,-3,6,-2,-4,-1,0,-1,-3,-2,-3],\n",
    "'M' : [-1,-2,-2,-4,-2,0,-2,-3,-1,2,3,-2,7,0,-3,-2,-1,-1,0,1],\n",
    "'F' : [-3,-3,-4,-5,-2,-4,-3,-4,-1,0,1,-4,0,8,-4,-3,-2,1,4,-1],\n",
    "'P' : [-1,-3,-2,-1,-4,-1,-1,-2,-2,-3,-4,-1,-3,-4,10,-1,-1,-4,-3,-3],\n",
    "'S' : [1,-1,1,0,-1,0,-1,0,-1,-3,-3,0,-2,-3,-1,5,2,-4,-2,-2],\n",
    "'T' : [0,-1,0,-1,-1,-1,-1,-2,-2,-1,-1,-1,-1,-2,-1,2,5,-3,-2,0],\n",
    "'W' : [-3,-3,-4,-5,-5,-1,-3,-3,-3,-3,-2,-3,-1,1,-4,-4,-3,15,2,-3],\n",
    "'Y' : [-2,-1,-2,-3,-3,-1,-2,-3,2,-1,-1,-2,0,4,-3,-2,-2,2,8,-1],\n",
    "'V' : [0,-3,-3,-4,-1,-3,-3,-4,-4,4,1,-3,1,-1,-3,-2,0,-3,-1,5]\n",
    "}\n",
    "\n",
    "size_dict = {'1p':6000,\n",
    "             '5p':30000,\n",
    "             '25':150500,\n",
    "             '50p':301000,\n",
    "             '75':451500}\n",
    "\n",
    "for key, val in zip(blosum_dict.keys(), blosum_dict.values()):\n",
    "    if len(val) != 20:\n",
    "        print(key +\":\"+ str(len(val)), end =\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = 5\n",
    "count = 0\n",
    "index_order = []\n",
    "\n",
    "for outer in range(cv):\n",
    "        test_idx = outer\n",
    "        for inner in range(cv):\n",
    "            if inner!=outer:\n",
    "                val_idx = inner\n",
    "                train_index = list()\n",
    "                for t in range(5):\n",
    "                    if t!=inner and t!=outer:\n",
    "                        train_index.append(t)\n",
    "                count += 1  \n",
    "                index_order.append([test_idx, val_idx, train_index])\n",
    "                \n",
    "index_order_nested = index_order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pep_max_len = 14\n",
    "hla_max_len = 34\n",
    "\n",
    "tgt_len = pep_max_len + hla_max_len\n",
    "\n",
    "d_ff = 512\n",
    "n_layers, n_heads = 1, 3\n",
    "\n",
    "batch_size = 1024\n",
    "epochs = 25\n",
    "threshold = 0.5\n",
    "\n",
    "vocab = np.load( data_dir + 'Transformer_vocab_dict.npy', allow_pickle = True).item()\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "id_blosum = 'OF_TData_pad14_{}_{}_hlac_pad'\n",
    "id_emb = 'OF_TData_pad14_{}_{}'\n",
    "\n",
    "save_attn = False\n",
    "save_attn_hla = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_df(l):\n",
    "    df = pd.DataFrame(l, columns =['05p', '1p', '25p', '75p', '100p'], index=['Blosum-20', 'embd-4', 'embd-20','embd-32','embd-64'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "START TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_list = []\n",
    "auc01_list = []\n",
    "ppv_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "['05p', 'Blosum_ED', 20]\n",
      "===== Model Start - 05p, Blosum_ED, 20 =====\n",
      "id: OF_TData_pad14_05p_Blosum_ED_hlac_pad_downsample0_125ep\n",
      "Transformer Blosum imported\n",
      "Will be saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_05p_Blosum_ED_hlac_pad_downsample0_125ep_d20_HLAperf.csv\n",
      "\tOF_TData_pad14_05p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL0.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14, 20])\n",
      "\t\t\t\t roc: 0.9373418442246954\n",
      "\n",
      "\tOF_TData_pad14_05p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL1.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14, 20])\n",
      "\t\t\t\t roc: 0.9372436639431267\n",
      "\n",
      "\tOF_TData_pad14_05p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL2.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14, 20])\n",
      "\t\t\t\t roc: 0.9372614752344435\n",
      "\n",
      "\tOF_TData_pad14_05p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL3.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14, 20])\n",
      "\t\t\t\t roc: 0.9361739872392841\n",
      "\n",
      "\t\t roc: 0.9454304755282377\n",
      "\tOF_TData_pad14_05p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL4.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14, 20])\n",
      "\t\t\t\t roc: 0.9375413799053293\n",
      "\n",
      "\tOF_TData_pad14_05p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL5.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14, 20])\n",
      "\t\t\t\t roc: 0.9377023816381658\n",
      "\n",
      "\tOF_TData_pad14_05p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL6.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14, 20])\n",
      "\t\t\t\t roc: 0.9383062557550176\n",
      "\n",
      "\tOF_TData_pad14_05p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL7.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14, 20])\n",
      "\t\t\t\t roc: 0.9379163532656477\n",
      "\n",
      "\t\t roc: 0.9446672896551243\n",
      "\tOF_TData_pad14_05p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL8.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14, 20])\n",
      "\t\t\t\t roc: 0.9324570557814243\n",
      "\n",
      "\tOF_TData_pad14_05p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL9.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14, 20])\n",
      "\t\t\t\t roc: 0.9361743409662496\n",
      "\n",
      "\tOF_TData_pad14_05p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL10.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14, 20])\n",
      "\t\t\t\t roc: 0.9354871367238111\n",
      "\n",
      "\tOF_TData_pad14_05p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL11.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14, 20])\n",
      "\t\t\t\t roc: 0.9358576300923839\n",
      "\n",
      "\t\t roc: 0.9431215391769043\n",
      "\tOF_TData_pad14_05p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL12.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14, 20])\n",
      "\t\t\t\t roc: 0.9371800457254034\n",
      "\n",
      "\tOF_TData_pad14_05p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL13.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14, 20])\n",
      "\t\t\t\t roc: 0.9381181564691807\n",
      "\n",
      "\tOF_TData_pad14_05p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL14.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14, 20])\n",
      "\t\t\t\t roc: 0.9362491316870869\n",
      "\n",
      "\tOF_TData_pad14_05p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL15.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14, 20])\n",
      "\t\t\t\t roc: 0.9344736044999554\n",
      "\n",
      "\t\t roc: 0.9438996463690461\n",
      "\tOF_TData_pad14_05p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL16.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14, 20])\n",
      "\t\t\t\t roc: 0.9339295193359175\n",
      "\n",
      "\tOF_TData_pad14_05p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL17.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14, 20])\n",
      "\t\t\t\t roc: 0.9364297739542812\n",
      "\n",
      "\tOF_TData_pad14_05p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL18.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14, 20])\n",
      "\t\t\t\t roc: 0.9361484715037792\n",
      "\n",
      "\tOF_TData_pad14_05p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL19.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14, 20])\n",
      "\t\t\t\t roc: 0.935089027126105\n",
      "\n",
      "\t\t roc: 0.9432832529967105\n",
      "\t===== Model End - 05p, Blosum_ED, 20 =====\n",
      "\t== Stats:\n",
      "\t  auc: 0.943644287406032\n",
      "\t  auc fpr 0.1: 0.6699147308618638\n",
      "\t  ppv: 0.7588468841705507\n",
      "tn = 1301220, fp = 204234, fn = 40916, tp = 318250\n",
      "y_pred: 0 = 1342136 | 1 = 522484\n",
      "y_true: 0 = 1505454 | 1 = 359166\n",
      "auc=0.9436|sensitivity=0.8861|specificity=0.8643|acc=0.8685|mcc=0.6589\n",
      "precision=0.6091|recall=0.8861|f1=0.7219|aupr=0.8204\n",
      "Saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_05p_Blosum_ED_hlac_pad_downsample0_125ep_d20_HLAperf.csv\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['1p', 'Blosum_ED', 20]\n",
      "===== Model Start - 1p, Blosum_ED, 20 =====\n",
      "id: OF_TData_pad14_1p_Blosum_ED_hlac_pad_downsample0_125ep\n",
      "Transformer Blosum imported\n",
      "Will be saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_1p_Blosum_ED_hlac_pad_downsample0_125ep_d20_HLAperf.csv\n",
      "\tOF_TData_pad14_1p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL0.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14, 20])\n",
      "\t\t\t\t roc: 0.9495991894440626\n",
      "\n",
      "\tOF_TData_pad14_1p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL1.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14, 20])\n",
      "\t\t\t\t roc: 0.9489846116615576\n",
      "\n",
      "\tOF_TData_pad14_1p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL2.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14, 20])\n",
      "\t\t\t\t roc: 0.9485863134229092\n",
      "\n",
      "\tOF_TData_pad14_1p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL3.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14, 20])\n",
      "\t\t\t\t roc: 0.9485915712884404\n",
      "\n",
      "\t\t roc: 0.9561516230618338\n",
      "\tOF_TData_pad14_1p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL4.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14, 20])\n",
      "\t\t\t\t roc: 0.950300861643222\n",
      "\n",
      "\tOF_TData_pad14_1p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL5.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14, 20])\n",
      "\t\t\t\t roc: 0.9495187091870941\n",
      "\n",
      "\tOF_TData_pad14_1p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL6.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14, 20])\n",
      "\t\t\t\t roc: 0.9484064852202139\n",
      "\n",
      "\tOF_TData_pad14_1p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL7.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14, 20])\n",
      "\t\t\t\t roc: 0.9500031842482112\n",
      "\n",
      "\t\t roc: 0.9565719679592912\n",
      "\tOF_TData_pad14_1p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL8.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14, 20])\n",
      "\t\t\t\t roc: 0.9481790454432006\n",
      "\n",
      "\tOF_TData_pad14_1p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL9.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14, 20])\n",
      "\t\t\t\t roc: 0.9486638601575939\n",
      "\n",
      "\tOF_TData_pad14_1p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL10.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14, 20])\n",
      "\t\t\t\t roc: 0.9494960167949784\n",
      "\n",
      "\tOF_TData_pad14_1p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL11.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14, 20])\n",
      "\t\t\t\t roc: 0.9492585086036509\n",
      "\n",
      "\t\t roc: 0.9557409159096981\n",
      "\tOF_TData_pad14_1p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL12.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14, 20])\n",
      "\t\t\t\t roc: 0.9487160912904474\n",
      "\n",
      "\tOF_TData_pad14_1p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL13.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14, 20])\n",
      "\t\t\t\t roc: 0.9488923021054995\n",
      "\n",
      "\tOF_TData_pad14_1p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL14.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14, 20])\n",
      "\t\t\t\t roc: 0.9505627456447314\n",
      "\n",
      "\tOF_TData_pad14_1p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL15.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14, 20])\n",
      "\t\t\t\t roc: 0.9496542073004861\n",
      "\n",
      "\t\t roc: 0.9562267197388674\n",
      "\tOF_TData_pad14_1p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL16.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14, 20])\n",
      "\t\t\t\t roc: 0.9490489894022219\n",
      "\n",
      "\tOF_TData_pad14_1p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL17.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14, 20])\n",
      "\t\t\t\t roc: 0.9500353061307835\n",
      "\n",
      "\tOF_TData_pad14_1p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL18.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14, 20])\n",
      "\t\t\t\t roc: 0.94996235366496\n",
      "\n",
      "\tOF_TData_pad14_1p_Blosum_ED_hlac_pad_downsample0_125ep_d20_layer1_multihead3_MODEL19.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14, 20])\n",
      "\t\t\t\t roc: 0.9500573935633895\n",
      "\n",
      "\t\t roc: 0.956593081939445\n",
      "\t===== Model End - 1p, Blosum_ED, 20 =====\n",
      "\t== Stats:\n",
      "\t  auc: 0.95614069803628\n",
      "\t  auc fpr 0.1: 0.7316588156648081\n",
      "\t  ppv: 0.7925499629697689\n",
      "tn = 1327660, fp = 177794, fn = 34989, tp = 324177\n",
      "y_pred: 0 = 1362649 | 1 = 501971\n",
      "y_true: 0 = 1505454 | 1 = 359166\n",
      "auc=0.9561|sensitivity=0.9026|specificity=0.8819|acc=0.8859|mcc=0.6975\n",
      "precision=0.6458|recall=0.9026|f1=0.7529|aupr=0.8607\n",
      "Saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_1p_Blosum_ED_hlac_pad_downsample0_125ep_d20_HLAperf.csv\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['25p', 'Blosum_ED', 20]\n",
      "===== Model Start - 25p, Blosum_ED, 20 =====\n",
      "id: OF_TData_pad14_25p_Blosum_ED_hlac_pad\n",
      "Transformer Blosum imported\n",
      "Will be saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_25p_Blosum_ED_hlac_pad_d20_HLAperf.csv\n",
      "\tOF_TData_pad14_25p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL0.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14, 20])\n",
      "\t\t\t\t roc: 0.9746202466520868\n",
      "\n",
      "\tOF_TData_pad14_25p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL1.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14, 20])\n",
      "\t\t\t\t roc: 0.9740784467151862\n",
      "\n",
      "\tOF_TData_pad14_25p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL2.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14, 20])\n",
      "\t\t\t\t roc: 0.9738337595811957\n",
      "\n",
      "\tOF_TData_pad14_25p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL3.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14, 20])\n",
      "\t\t\t\t roc: 0.9737363233855507\n",
      "\n",
      "\t\t roc: 0.9780388645667573\n",
      "\tOF_TData_pad14_25p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL4.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14, 20])\n",
      "\t\t\t\t roc: 0.9735273804089793\n",
      "\n",
      "\tOF_TData_pad14_25p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL5.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14, 20])\n",
      "\t\t\t\t roc: 0.9737543884278842\n",
      "\n",
      "\tOF_TData_pad14_25p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL6.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14, 20])\n",
      "\t\t\t\t roc: 0.972826321902589\n",
      "\n",
      "\tOF_TData_pad14_25p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL7.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14, 20])\n",
      "\t\t\t\t roc: 0.9739255263503441\n",
      "\n",
      "\t\t roc: 0.9773409511055651\n",
      "\tOF_TData_pad14_25p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL8.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14, 20])\n",
      "\t\t\t\t roc: 0.9736903180693512\n",
      "\n",
      "\tOF_TData_pad14_25p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL9.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14, 20])\n",
      "\t\t\t\t roc: 0.9735126587982564\n",
      "\n",
      "\tOF_TData_pad14_25p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL10.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14, 20])\n",
      "\t\t\t\t roc: 0.9723444872794424\n",
      "\n",
      "\tOF_TData_pad14_25p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL11.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14, 20])\n",
      "\t\t\t\t roc: 0.9727828643117128\n",
      "\n",
      "\t\t roc: 0.9772082316332997\n",
      "\tOF_TData_pad14_25p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL12.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14, 20])\n",
      "\t\t\t\t roc: 0.9736405617110834\n",
      "\n",
      "\tOF_TData_pad14_25p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL13.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14, 20])\n",
      "\t\t\t\t roc: 0.9739878756014516\n",
      "\n",
      "\tOF_TData_pad14_25p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL14.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14, 20])\n",
      "\t\t\t\t roc: 0.9727510586273788\n",
      "\n",
      "\tOF_TData_pad14_25p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL15.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14, 20])\n",
      "\t\t\t\t roc: 0.9726147226426383\n",
      "\n",
      "\t\t roc: 0.9778067864017559\n",
      "\tOF_TData_pad14_25p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL16.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14, 20])\n",
      "\t\t\t\t roc: 0.973707300445946\n",
      "\n",
      "\tOF_TData_pad14_25p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL17.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14, 20])\n",
      "\t\t\t\t roc: 0.9743548792374905\n",
      "\n",
      "\tOF_TData_pad14_25p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL18.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14, 20])\n",
      "\t\t\t\t roc: 0.9738404246261492\n",
      "\n",
      "\tOF_TData_pad14_25p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL19.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14, 20])\n",
      "\t\t\t\t roc: 0.9722916333270682\n",
      "\n",
      "\t\t roc: 0.9778889339183932\n",
      "\t===== Model End - 25p, Blosum_ED, 20 =====\n",
      "\t== Stats:\n",
      "\t  auc: 0.9776313674394705\n",
      "\t  auc fpr 0.1: 0.8440017908759969\n",
      "\t  ppv: 0.8580739825039119\n",
      "tn = 1391994, fp = 113460, fn = 25937, tp = 333229\n",
      "y_pred: 0 = 1417931 | 1 = 446689\n",
      "y_true: 0 = 1505454 | 1 = 359166\n",
      "auc=0.9776|sensitivity=0.9278|specificity=0.9246|acc=0.9252|mcc=0.7876\n",
      "precision=0.7460|recall=0.9278|f1=0.8270|aupr=0.9249\n",
      "Saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_25p_Blosum_ED_hlac_pad_d20_HLAperf.csv\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['75p', 'Blosum_ED', 20]\n",
      "===== Model Start - 75p, Blosum_ED, 20 =====\n",
      "id: OF_TData_pad14_75p_Blosum_ED_hlac_pad\n",
      "Transformer Blosum imported\n",
      "Will be saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_75p_Blosum_ED_hlac_pad_d20_HLAperf.csv\n",
      "\tOF_TData_pad14_75p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL0.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14, 20])\n",
      "\t\t\t\t roc: 0.9779551143856139\n",
      "\n",
      "\tOF_TData_pad14_75p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL1.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14, 20])\n",
      "\t\t\t\t roc: 0.9773134025606341\n",
      "\n",
      "\tOF_TData_pad14_75p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL2.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14, 20])\n",
      "\t\t\t\t roc: 0.9776124852566924\n",
      "\n",
      "\tOF_TData_pad14_75p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL3.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14, 20])\n",
      "\t\t\t\t roc: 0.9767771488710393\n",
      "\n",
      "\t\t roc: 0.9808645255984354\n",
      "\tOF_TData_pad14_75p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL4.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14, 20])\n",
      "\t\t\t\t roc: 0.9767105935383138\n",
      "\n",
      "\tOF_TData_pad14_75p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL5.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14, 20])\n",
      "\t\t\t\t roc: 0.976834586639951\n",
      "\n",
      "\tOF_TData_pad14_75p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL6.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14, 20])\n",
      "\t\t\t\t roc: 0.9774319709562169\n",
      "\n",
      "\tOF_TData_pad14_75p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL7.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14, 20])\n",
      "\t\t\t\t roc: 0.9769127562746598\n",
      "\n",
      "\t\t roc: 0.9804380781969192\n",
      "\tOF_TData_pad14_75p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL8.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14, 20])\n",
      "\t\t\t\t roc: 0.9765949729947592\n",
      "\n",
      "\tOF_TData_pad14_75p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL9.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14, 20])\n",
      "\t\t\t\t roc: 0.9769844767670535\n",
      "\n",
      "\tOF_TData_pad14_75p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL10.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14, 20])\n",
      "\t\t\t\t roc: 0.9767972026001511\n",
      "\n",
      "\tOF_TData_pad14_75p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL11.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14, 20])\n",
      "\t\t\t\t roc: 0.9762937336029895\n",
      "\n",
      "\t\t roc: 0.9800591722455688\n",
      "\tOF_TData_pad14_75p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL12.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14, 20])\n",
      "\t\t\t\t roc: 0.9776511222177978\n",
      "\n",
      "\tOF_TData_pad14_75p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL13.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14, 20])\n",
      "\t\t\t\t roc: 0.9771959542317721\n",
      "\n",
      "\tOF_TData_pad14_75p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL14.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14, 20])\n",
      "\t\t\t\t roc: 0.9768079474774596\n",
      "\n",
      "\tOF_TData_pad14_75p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL15.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14, 20])\n",
      "\t\t\t\t roc: 0.9769928891967239\n",
      "\n",
      "\t\t roc: 0.9802708188422423\n",
      "\tOF_TData_pad14_75p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL16.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14, 20])\n",
      "\t\t\t\t roc: 0.9765535829377234\n",
      "\n",
      "\tOF_TData_pad14_75p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL17.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14, 20])\n",
      "\t\t\t\t roc: 0.9769135364809627\n",
      "\n",
      "\tOF_TData_pad14_75p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL18.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14, 20])\n",
      "\t\t\t\t roc: 0.9770094237343434\n",
      "\n",
      "\tOF_TData_pad14_75p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL19.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14, 20])\n",
      "\t\t\t\t roc: 0.9771507634455451\n",
      "\n",
      "\t\t roc: 0.9802016379371439\n",
      "\t===== Model End - 75p, Blosum_ED, 20 =====\n",
      "\t== Stats:\n",
      "\t  auc: 0.9803389982793068\n",
      "\t  auc fpr 0.1: 0.8611414801611329\n",
      "\t  ppv: 0.8683700572994103\n",
      "tn = 1403253, fp = 102201, fn = 24873, tp = 334293\n",
      "y_pred: 0 = 1428126 | 1 = 436494\n",
      "y_true: 0 = 1505454 | 1 = 359166\n",
      "auc=0.9803|sensitivity=0.9307|specificity=0.9321|acc=0.9318|mcc=0.8036\n",
      "precision=0.7659|recall=0.9307|f1=0.8403|aupr=0.9343\n",
      "Saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_75p_Blosum_ED_hlac_pad_d20_HLAperf.csv\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['100p', 'Blosum_ED', 20]\n",
      "===== Model Start - 100p, Blosum_ED, 20 =====\n",
      "id: OF_TData_pad14_100p_Blosum_ED_hlac_pad\n",
      "Transformer Blosum imported\n",
      "Will be saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_100p_Blosum_ED_hlac_pad_d20_HLAperf.csv\n",
      "\tOF_TData_pad14_100p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL0.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14, 20])\n",
      "\t\t\t\t roc: 0.9773021484688066\n",
      "\n",
      "\tOF_TData_pad14_100p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL1.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14, 20])\n",
      "\t\t\t\t roc: 0.9780436473133882\n",
      "\n",
      "\tOF_TData_pad14_100p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL2.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14, 20])\n",
      "\t\t\t\t roc: 0.9788344825036552\n",
      "\n",
      "\tOF_TData_pad14_100p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL3.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14, 20])\n",
      "\t\t\t\t roc: 0.9783577210599791\n",
      "\n",
      "\t\t roc: 0.9815827322589258\n",
      "\tOF_TData_pad14_100p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL4.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14, 20])\n",
      "\t\t\t\t roc: 0.9768627287741627\n",
      "\n",
      "\tOF_TData_pad14_100p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL5.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14, 20])\n",
      "\t\t\t\t roc: 0.9774227277219365\n",
      "\n",
      "\tOF_TData_pad14_100p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL6.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14, 20])\n",
      "\t\t\t\t roc: 0.9773180668389022\n",
      "\n",
      "\tOF_TData_pad14_100p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL7.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14, 20])\n",
      "\t\t\t\t roc: 0.9777169810616287\n",
      "\n",
      "\t\t roc: 0.9804317333077891\n",
      "\tOF_TData_pad14_100p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL8.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14, 20])\n",
      "\t\t\t\t roc: 0.9771991147010765\n",
      "\n",
      "\tOF_TData_pad14_100p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL9.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14, 20])\n",
      "\t\t\t\t roc: 0.977099680750899\n",
      "\n",
      "\tOF_TData_pad14_100p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL10.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14, 20])\n",
      "\t\t\t\t roc: 0.9766686619409479\n",
      "\n",
      "\tOF_TData_pad14_100p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL11.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14, 20])\n",
      "\t\t\t\t roc: 0.9769292407495215\n",
      "\n",
      "\t\t roc: 0.9804868674526271\n",
      "\tOF_TData_pad14_100p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL12.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14, 20])\n",
      "\t\t\t\t roc: 0.9782771009900458\n",
      "\n",
      "\tOF_TData_pad14_100p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL13.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14, 20])\n",
      "\t\t\t\t roc: 0.9776537921194066\n",
      "\n",
      "\tOF_TData_pad14_100p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL14.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14, 20])\n",
      "\t\t\t\t roc: 0.9771282430121591\n",
      "\n",
      "\tOF_TData_pad14_100p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL15.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14, 20])\n",
      "\t\t\t\t roc: 0.9771214131354268\n",
      "\n",
      "\t\t roc: 0.9809435477227371\n",
      "\tOF_TData_pad14_100p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL16.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14, 20])\n",
      "\t\t\t\t roc: 0.978067872342997\n",
      "\n",
      "\tOF_TData_pad14_100p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL17.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14, 20])\n",
      "\t\t\t\t roc: 0.9778998988665539\n",
      "\n",
      "\tOF_TData_pad14_100p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL18.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14, 20])\n",
      "\t\t\t\t roc: 0.977882307215267\n",
      "\n",
      "\tOF_TData_pad14_100p_Blosum_ED_hlac_pad_d20_layer1_multihead3_MODEL19.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14, 20])\n",
      "\t\t\t\t roc: 0.9772528999675416\n",
      "\n",
      "\t\t roc: 0.9811302983618493\n",
      "\t===== Model End - 100p, Blosum_ED, 20 =====\n",
      "\t== Stats:\n",
      "\t  auc: 0.9809006586912417\n",
      "\t  auc fpr 0.1: 0.8649963930638129\n",
      "\t  ppv: 0.8707951198053268\n",
      "tn = 1410398, fp = 95056, fn = 25568, tp = 333598\n",
      "y_pred: 0 = 1435966 | 1 = 428654\n",
      "y_true: 0 = 1505454 | 1 = 359166\n",
      "auc=0.9809|sensitivity=0.9288|specificity=0.9369|acc=0.9353|mcc=0.8114\n",
      "precision=0.7782|recall=0.9288|f1=0.8469|aupr=0.9362\n",
      "Saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_100p_Blosum_ED_hlac_pad_d20_HLAperf.csv\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['05p', 'EmbeddingAttention', 4]\n",
      "===== Model Start - 05p, EmbeddingAttention, 4 =====\n",
      "Transformer Embedding imported\n",
      "Will be saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d4_HLAperf.csv\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL0.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.808322201357059\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL1.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.7734271023571853\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL2.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.7831418913162018\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL3.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.7803878087325056\n",
      "\n",
      "\t\t roc: 0.8381633496431442\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL4.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.7888877559585665\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL5.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.7823357522003149\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL6.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.7711614677122386\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL7.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.7760798992538391\n",
      "\n",
      "\t\t roc: 0.8032225369879286\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL8.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.7732640682837882\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL9.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.7788931032021591\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL10.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.7748094591013548\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL11.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.7727239552197142\n",
      "\n",
      "\t\t roc: 0.8057032216801744\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL12.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.7784912160608028\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL13.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.7672594229574291\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL14.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.7856737814017133\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL15.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.7775560410604254\n",
      "\n",
      "\t\t roc: 0.8062400019663654\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL16.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.7884004994323915\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL17.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.7671200254625877\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL18.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.7748261273859959\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL19.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.7792167387823818\n",
      "\n",
      "\t\t roc: 0.8053546128667499\n",
      "\t===== Model End - 05p, EmbeddingAttention, 4 =====\n",
      "\t== Stats:\n",
      "\t  auc: 0.8112330965319888\n",
      "\t  auc fpr 0.1: 0.3195614163187414\n",
      "\t  ppv: 0.5242422723754475\n",
      "tn = 1069045, fp = 436409, fn = 85165, tp = 274001\n",
      "y_pred: 0 = 1154210 | 1 = 710410\n",
      "y_true: 0 = 1505454 | 1 = 359166\n",
      "auc=0.8112|sensitivity=0.7629|specificity=0.7101|acc=0.7203|mcc=0.3841\n",
      "precision=0.3857|recall=0.7629|f1=0.5124|aupr=0.5332\n",
      "Saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d4_HLAperf.csv\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['1p', 'EmbeddingAttention', 4]\n",
      "===== Model Start - 1p, EmbeddingAttention, 4 =====\n",
      "Transformer Embedding imported\n",
      "Will be saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d4_HLAperf.csv\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL0.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.8536876644323094\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL1.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.8401789055705963\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL2.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.8291735518190486\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL3.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.8142909423909745\n",
      "\n",
      "\t\t roc: 0.8798291906576924\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL4.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.8311630105940668\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL5.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.8226568286764119\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL6.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.8274078295826779\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL7.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.8312639368972352\n",
      "\n",
      "\t\t roc: 0.8610982178866672\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL8.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.839212170280268\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL9.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.8234081793241974\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL10.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.8334766236147096\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL11.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.8322976964940193\n",
      "\n",
      "\t\t roc: 0.8653040862942944\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL12.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.8267120377469723\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL13.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.8276453028113049\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL14.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.8327247993334256\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL15.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.8142140779145239\n",
      "\n",
      "\t\t roc: 0.8593850443252592\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL16.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.818626100887869\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL17.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.8283114548143823\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL18.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.833083713208036\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d4_layer1_multihead3_MODEL19.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.8181496010090643\n",
      "\n",
      "\t\t roc: 0.8616457663616426\n",
      "\t===== Model End - 1p, EmbeddingAttention, 4 =====\n",
      "\t== Stats:\n",
      "\t  auc: 0.8637315140044846\n",
      "\t  auc fpr 0.1: 0.4053133721132728\n",
      "\t  ppv: 0.6015825551416337\n",
      "tn = 1159660, fp = 345794, fn = 69422, tp = 289744\n",
      "y_pred: 0 = 1229082 | 1 = 635538\n",
      "y_true: 0 = 1505454 | 1 = 359166\n",
      "auc=0.8637|sensitivity=0.8067|specificity=0.7703|acc=0.7773|mcc=0.4801\n",
      "precision=0.4559|recall=0.8067|f1=0.5826|aupr=0.6212\n",
      "Saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d4_HLAperf.csv\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['25p', 'EmbeddingAttention', 4]\n",
      "===== Model Start - 25p, EmbeddingAttention, 4 =====\n",
      "Transformer Embedding imported\n",
      "Will be saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_25p_EmbeddingAttention_d4_HLAperf.csv\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d4_layer1_multihead3_MODEL0.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9594051054278763\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d4_layer1_multihead3_MODEL1.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9557534815724849\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d4_layer1_multihead3_MODEL2.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.955564116206548\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d4_layer1_multihead3_MODEL3.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9572009923514202\n",
      "\n",
      "\t\t roc: 0.9657798115880114\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d4_layer1_multihead3_MODEL4.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.954796360468551\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d4_layer1_multihead3_MODEL5.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9548974793758462\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d4_layer1_multihead3_MODEL6.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9568863881277341\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d4_layer1_multihead3_MODEL7.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9550760620431037\n",
      "\n",
      "\t\t roc: 0.9619415691565153\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d4_layer1_multihead3_MODEL8.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9545915705032261\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d4_layer1_multihead3_MODEL9.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9545432448228547\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d4_layer1_multihead3_MODEL10.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9537738001073084\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d4_layer1_multihead3_MODEL11.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9576233817407501\n",
      "\n",
      "\t\t roc: 0.9630086510229006\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d4_layer1_multihead3_MODEL12.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9540250549347329\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d4_layer1_multihead3_MODEL13.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9571091669605977\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d4_layer1_multihead3_MODEL14.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9539355661476794\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d4_layer1_multihead3_MODEL15.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9550301129654644\n",
      "\n",
      "\t\t roc: 0.9612585804928919\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d4_layer1_multihead3_MODEL16.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9572104877532015\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d4_layer1_multihead3_MODEL17.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9565380582792106\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d4_layer1_multihead3_MODEL18.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9565744716791338\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d4_layer1_multihead3_MODEL19.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9557380672918667\n",
      "\n",
      "\t\t roc: 0.9626460083923839\n",
      "\t===== Model End - 25p, EmbeddingAttention, 4 =====\n",
      "\t== Stats:\n",
      "\t  auc: 0.9628800207911368\n",
      "\t  auc fpr 0.1: 0.7660488714453739\n",
      "\t  ppv: 0.8121035955519175\n",
      "tn = 1347523, fp = 157931, fn = 35479, tp = 323687\n",
      "y_pred: 0 = 1383002 | 1 = 481618\n",
      "y_true: 0 = 1505454 | 1 = 359166\n",
      "auc=0.9629|sensitivity=0.9012|specificity=0.8951|acc=0.8963|mcc=0.7175\n",
      "precision=0.6721|recall=0.9012|f1=0.7700|aupr=0.8817\n",
      "Saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_25p_EmbeddingAttention_d4_HLAperf.csv\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['75p', 'EmbeddingAttention', 4]\n",
      "===== Model Start - 75p, EmbeddingAttention, 4 =====\n",
      "Transformer Embedding imported\n",
      "Will be saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_75p_EmbeddingAttention_d4_HLAperf.csv\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d4_layer1_multihead3_MODEL0.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.966430617088553\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d4_layer1_multihead3_MODEL1.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9642496653024435\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d4_layer1_multihead3_MODEL2.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9649298819810862\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d4_layer1_multihead3_MODEL3.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9655084865380844\n",
      "\n",
      "\t\t roc: 0.9699533712272109\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d4_layer1_multihead3_MODEL4.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9655578221583957\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d4_layer1_multihead3_MODEL5.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9657812330358777\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d4_layer1_multihead3_MODEL6.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9652503644701691\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d4_layer1_multihead3_MODEL7.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9642488124035445\n",
      "\n",
      "\t\t roc: 0.9693952848411042\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d4_layer1_multihead3_MODEL8.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9658087124868754\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d4_layer1_multihead3_MODEL9.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9649977163424253\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d4_layer1_multihead3_MODEL10.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9663372444411443\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d4_layer1_multihead3_MODEL11.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9672043011862459\n",
      "\n",
      "\t\t roc: 0.9719068557590937\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d4_layer1_multihead3_MODEL12.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9643527970819525\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d4_layer1_multihead3_MODEL13.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9650697006601938\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d4_layer1_multihead3_MODEL14.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9661564563345901\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d4_layer1_multihead3_MODEL15.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9651872018503085\n",
      "\n",
      "\t\t roc: 0.9692907779846924\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d4_layer1_multihead3_MODEL16.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9656666336196627\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d4_layer1_multihead3_MODEL17.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9643206553506474\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d4_layer1_multihead3_MODEL18.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9654217936268388\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d4_layer1_multihead3_MODEL19.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.968844343408999\n",
      "\n",
      "\t\t roc: 0.9716170509874035\n",
      "\t===== Model End - 75p, EmbeddingAttention, 4 =====\n",
      "\t== Stats:\n",
      "\t  auc: 0.9704175947614716\n",
      "\t  auc fpr 0.1: 0.8056479138284744\n",
      "\t  ppv: 0.8348618744535953\n",
      "tn = 1369317, fp = 136137, fn = 31458, tp = 327708\n",
      "y_pred: 0 = 1400775 | 1 = 463845\n",
      "y_true: 0 = 1505454 | 1 = 359166\n",
      "auc=0.9704|sensitivity=0.9124|specificity=0.9096|acc=0.9101|mcc=0.7498\n",
      "precision=0.7065|recall=0.9124|f1=0.7964|aupr=0.9048\n",
      "Saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_75p_EmbeddingAttention_d4_HLAperf.csv\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['100p', 'EmbeddingAttention', 4]\n",
      "===== Model Start - 100p, EmbeddingAttention, 4 =====\n",
      "Transformer Embedding imported\n",
      "Will be saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_100p_EmbeddingAttention_d4_HLAperf.csv\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d4_layer1_multihead3_MODEL0.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9697925162272374\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d4_layer1_multihead3_MODEL1.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9680754336589126\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d4_layer1_multihead3_MODEL2.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.968054515037815\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d4_layer1_multihead3_MODEL3.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9688168282963753\n",
      "\n",
      "\t\t roc: 0.9735617865956885\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d4_layer1_multihead3_MODEL4.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9668245508630118\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d4_layer1_multihead3_MODEL5.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9670903903247011\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d4_layer1_multihead3_MODEL6.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9665146951733359\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d4_layer1_multihead3_MODEL7.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9670631474352309\n",
      "\n",
      "\t\t roc: 0.9708601203858805\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d4_layer1_multihead3_MODEL8.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9672517889431234\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d4_layer1_multihead3_MODEL9.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.966588147455216\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d4_layer1_multihead3_MODEL10.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9687323510196544\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d4_layer1_multihead3_MODEL11.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9661421232208309\n",
      "\n",
      "\t\t roc: 0.9723153377286243\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d4_layer1_multihead3_MODEL12.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9675436042316309\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d4_layer1_multihead3_MODEL13.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.966584794970364\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d4_layer1_multihead3_MODEL14.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9659480286449268\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d4_layer1_multihead3_MODEL15.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9671051230320629\n",
      "\n",
      "\t\t roc: 0.9711113220305672\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d4_layer1_multihead3_MODEL16.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9687389526689907\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d4_layer1_multihead3_MODEL17.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9675918331452316\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d4_layer1_multihead3_MODEL18.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9670707423638815\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d4_layer1_multihead3_MODEL19.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9678779284119918\n",
      "\n",
      "\t\t roc: 0.9718705415972146\n",
      "\t===== Model End - 100p, EmbeddingAttention, 4 =====\n",
      "\t== Stats:\n",
      "\t  auc: 0.9719321925333557\n",
      "\t  auc fpr 0.1: 0.8146162350226912\n",
      "\t  ppv: 0.8399765011164754\n",
      "tn = 1371700, fp = 133754, fn = 30059, tp = 329107\n",
      "y_pred: 0 = 1401759 | 1 = 462861\n",
      "y_true: 0 = 1505454 | 1 = 359166\n",
      "auc=0.9719|sensitivity=0.9163|specificity=0.9112|acc=0.9121|mcc=0.7554\n",
      "precision=0.7110|recall=0.9163|f1=0.8007|aupr=0.9099\n",
      "Saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_100p_EmbeddingAttention_d4_HLAperf.csv\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['05p', 'EmbeddingAttention', 20]\n",
      "===== Model Start - 05p, EmbeddingAttention, 20 =====\n",
      "Transformer Embedding imported\n",
      "Will be saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d20_HLAperf.csv\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL0.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9265300801057369\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL1.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9257193524366938\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL2.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9275500156859532\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL3.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9268658433152309\n",
      "\n",
      "\t\t roc: 0.9341043585748311\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL4.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9285273622205494\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL5.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9268083743786688\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL6.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.928105893704106\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL7.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9277666173220835\n",
      "\n",
      "\t\t roc: 0.9355376263162551\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL8.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9236405889769483\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL9.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9261199800190283\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL10.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9268299060406334\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL11.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9230935178324323\n",
      "\n",
      "\t\t roc: 0.9324763258716058\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL12.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9284965130170701\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL13.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9283413382706082\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL14.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9280297546630213\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL15.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9264314128508478\n",
      "\n",
      "\t\t roc: 0.935381586638865\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL16.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9283674639035954\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL17.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9294423169428937\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL18.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9256671272900314\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL19.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9267582943650297\n",
      "\n",
      "\t\t roc: 0.9347740885420216\n",
      "\t===== Model End - 05p, EmbeddingAttention, 20 =====\n",
      "\t== Stats:\n",
      "\t  auc: 0.9343052044415473\n",
      "\t  auc fpr 0.1: 0.6295147844843577\n",
      "\t  ppv: 0.7354176063435849\n",
      "tn = 1287903, fp = 217551, fn = 46933, tp = 312233\n",
      "y_pred: 0 = 1334836 | 1 = 529784\n",
      "y_true: 0 = 1505454 | 1 = 359166\n",
      "auc=0.9343|sensitivity=0.8693|specificity=0.8555|acc=0.8582|mcc=0.6338\n",
      "precision=0.5894|recall=0.8693|f1=0.7025|aupr=0.7947\n",
      "Saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d20_HLAperf.csv\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['1p', 'EmbeddingAttention', 20]\n",
      "===== Model Start - 1p, EmbeddingAttention, 20 =====\n",
      "Transformer Embedding imported\n",
      "Will be saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d20_HLAperf.csv\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL0.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9432534825968957\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL1.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9437906132284111\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL2.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9455003916718294\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL3.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9431285556444644\n",
      "\n",
      "\t\t roc: 0.9492326383866991\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL4.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9428961718201957\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL5.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9453930318924012\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL6.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9452665275105168\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL7.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9446537210088455\n",
      "\n",
      "\t\t roc: 0.9501929660366523\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL8.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9426212917068056\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL9.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.944279278106621\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL10.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9451244478285783\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL11.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9450602951694038\n",
      "\n",
      "\t\t roc: 0.9497128054655808\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL12.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9455550976283451\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL13.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.945160114307568\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL14.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9456374322344167\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL15.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9431749154331708\n",
      "\n",
      "\t\t roc: 0.950496176229415\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL16.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9429839958445587\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL17.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9447535801510132\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL18.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9456740803064999\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d20_layer1_multihead3_MODEL19.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9427153584289419\n",
      "\n",
      "\t\t roc: 0.9497145515488212\n",
      "\t===== Model End - 1p, EmbeddingAttention, 20 =====\n",
      "\t== Stats:\n",
      "\t  auc: 0.9498005461016522\n",
      "\t  auc fpr 0.1: 0.701895681160884\n",
      "\t  ppv: 0.7754742932237462\n",
      "tn = 1325657, fp = 179797, fn = 41638, tp = 317528\n",
      "y_pred: 0 = 1367295 | 1 = 497325\n",
      "y_true: 0 = 1505454 | 1 = 359166\n",
      "auc=0.9498|sensitivity=0.8841|specificity=0.8806|acc=0.8812|mcc=0.6818\n",
      "precision=0.6385|recall=0.8841|f1=0.7415|aupr=0.8427\n",
      "Saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d20_HLAperf.csv\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['25p', 'EmbeddingAttention', 20]\n",
      "===== Model Start - 25p, EmbeddingAttention, 20 =====\n",
      "Transformer Embedding imported\n",
      "Will be saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_25p_EmbeddingAttention_d20_HLAperf.csv\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d20_layer1_multihead3_MODEL0.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9734576139661566\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d20_layer1_multihead3_MODEL1.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9743437878202053\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d20_layer1_multihead3_MODEL2.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9743246208667582\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d20_layer1_multihead3_MODEL3.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9744772985628113\n",
      "\n",
      "\t\t roc: 0.977673088344959\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d20_layer1_multihead3_MODEL4.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9734794453751285\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d20_layer1_multihead3_MODEL5.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9736581739749983\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d20_layer1_multihead3_MODEL6.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9738540991365272\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d20_layer1_multihead3_MODEL7.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9741601445414736\n",
      "\n",
      "\t\t roc: 0.9771507784228822\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d20_layer1_multihead3_MODEL8.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9733797775002193\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d20_layer1_multihead3_MODEL9.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9733287524632532\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d20_layer1_multihead3_MODEL10.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9741372145376566\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d20_layer1_multihead3_MODEL11.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9737477976974395\n",
      "\n",
      "\t\t roc: 0.9770039602801079\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d20_layer1_multihead3_MODEL12.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9736896181865233\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d20_layer1_multihead3_MODEL13.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9739815927198978\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d20_layer1_multihead3_MODEL14.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9745968366247677\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d20_layer1_multihead3_MODEL15.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9738670539524799\n",
      "\n",
      "\t\t roc: 0.977236834361179\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d20_layer1_multihead3_MODEL16.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9743342314144625\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d20_layer1_multihead3_MODEL17.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9745475178730493\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d20_layer1_multihead3_MODEL18.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9744711596731321\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d20_layer1_multihead3_MODEL19.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.97408072214662\n",
      "\n",
      "\t\t roc: 0.9777057934845514\n",
      "\t===== Model End - 25p, EmbeddingAttention, 20 =====\n",
      "\t== Stats:\n",
      "\t  auc: 0.9773397092909234\n",
      "\t  auc fpr 0.1: 0.8425653073949797\n",
      "\t  ppv: 0.8573055356019222\n",
      "tn = 1389804, fp = 115650, fn = 25774, tp = 333392\n",
      "y_pred: 0 = 1415578 | 1 = 449042\n",
      "y_true: 0 = 1505454 | 1 = 359166\n",
      "auc=0.9773|sensitivity=0.9282|specificity=0.9232|acc=0.9242|mcc=0.7853\n",
      "precision=0.7425|recall=0.9282|f1=0.8250|aupr=0.9242\n",
      "Saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_25p_EmbeddingAttention_d20_HLAperf.csv\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['75p', 'EmbeddingAttention', 20]\n",
      "===== Model Start - 75p, EmbeddingAttention, 20 =====\n",
      "Transformer Embedding imported\n",
      "Will be saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_75p_EmbeddingAttention_d20_HLAperf.csv\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d20_layer1_multihead3_MODEL0.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9775915662893151\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d20_layer1_multihead3_MODEL1.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.977653919198407\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d20_layer1_multihead3_MODEL2.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9774139907561474\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d20_layer1_multihead3_MODEL3.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9767993045880812\n",
      "\n",
      "\t\t roc: 0.9804370121760236\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d20_layer1_multihead3_MODEL4.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.977172278882619\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d20_layer1_multihead3_MODEL5.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9763592656707536\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d20_layer1_multihead3_MODEL6.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.977102147540189\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d20_layer1_multihead3_MODEL7.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9767064301653581\n",
      "\n",
      "\t\t roc: 0.9799996339208008\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d20_layer1_multihead3_MODEL8.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9765268948205393\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d20_layer1_multihead3_MODEL9.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9763678687003197\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d20_layer1_multihead3_MODEL10.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.976646000274388\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d20_layer1_multihead3_MODEL11.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9760983599790896\n",
      "\n",
      "\t\t roc: 0.9795748965100535\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d20_layer1_multihead3_MODEL12.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9767159414639721\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d20_layer1_multihead3_MODEL13.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.977457383452865\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d20_layer1_multihead3_MODEL14.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9771806795688842\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d20_layer1_multihead3_MODEL15.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9769902420305158\n",
      "\n",
      "\t\t roc: 0.9804111420130618\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d20_layer1_multihead3_MODEL16.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9766932147727024\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d20_layer1_multihead3_MODEL17.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9770655640501782\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d20_layer1_multihead3_MODEL18.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9769502598983223\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d20_layer1_multihead3_MODEL19.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9772069511877057\n",
      "\n",
      "\t\t roc: 0.97983396249651\n",
      "\t===== Model End - 75p, EmbeddingAttention, 20 =====\n",
      "\t== Stats:\n",
      "\t  auc: 0.9800188877653593\n",
      "\t  auc fpr 0.1: 0.860167950448681\n",
      "\t  ppv: 0.8677380375648029\n",
      "tn = 1401174, fp = 104280, fn = 24734, tp = 334432\n",
      "y_pred: 0 = 1425908 | 1 = 438712\n",
      "y_true: 0 = 1505454 | 1 = 359166\n",
      "auc=0.9800|sensitivity=0.9311|specificity=0.9307|acc=0.9308|mcc=0.8013\n",
      "precision=0.7623|recall=0.9311|f1=0.8383|aupr=0.9336\n",
      "Saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_75p_EmbeddingAttention_d20_HLAperf.csv\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['100p', 'EmbeddingAttention', 20]\n",
      "===== Model Start - 100p, EmbeddingAttention, 20 =====\n",
      "Transformer Embedding imported\n",
      "Will be saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_100p_EmbeddingAttention_d20_HLAperf.csv\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d20_layer1_multihead3_MODEL0.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9777676508342268\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d20_layer1_multihead3_MODEL1.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9782382276985087\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d20_layer1_multihead3_MODEL2.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9782825241963926\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d20_layer1_multihead3_MODEL3.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9778443589780624\n",
      "\n",
      "\t\t roc: 0.9813190795216195\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d20_layer1_multihead3_MODEL4.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9774762606918116\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d20_layer1_multihead3_MODEL5.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9773967210357956\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d20_layer1_multihead3_MODEL6.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9775262761705064\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d20_layer1_multihead3_MODEL7.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9773028918895215\n",
      "\n",
      "\t\t roc: 0.9804921457192532\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d20_layer1_multihead3_MODEL8.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9766305059263811\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d20_layer1_multihead3_MODEL9.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9772767995403008\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d20_layer1_multihead3_MODEL10.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9773337412992824\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d20_layer1_multihead3_MODEL11.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9771065525235103\n",
      "\n",
      "\t\t roc: 0.9802273104890034\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d20_layer1_multihead3_MODEL12.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.977566247023508\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d20_layer1_multihead3_MODEL13.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9777703963515691\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d20_layer1_multihead3_MODEL14.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9775688203692625\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d20_layer1_multihead3_MODEL15.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9774770811023423\n",
      "\n",
      "\t\t roc: 0.9808197237017221\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d20_layer1_multihead3_MODEL16.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9777220754201656\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d20_layer1_multihead3_MODEL17.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9775418932034008\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d20_layer1_multihead3_MODEL18.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9779620212183641\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d20_layer1_multihead3_MODEL19.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9770531688903884\n",
      "\n",
      "\t\t roc: 0.981058034106242\n",
      "\t===== Model End - 100p, EmbeddingAttention, 20 =====\n",
      "\t== Stats:\n",
      "\t  auc: 0.9807753237070804\n",
      "\t  auc fpr 0.1: 0.8641186102746573\n",
      "\t  ppv: 0.8702828218706671\n",
      "tn = 1406928, fp = 98526, fn = 24689, tp = 334477\n",
      "y_pred: 0 = 1431617 | 1 = 433003\n",
      "y_true: 0 = 1505454 | 1 = 359166\n",
      "auc=0.9808|sensitivity=0.9313|specificity=0.9346|acc=0.9339|mcc=0.8086\n",
      "precision=0.7725|recall=0.9313|f1=0.8445|aupr=0.9355\n",
      "Saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_100p_EmbeddingAttention_d20_HLAperf.csv\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['05p', 'EmbeddingAttention', 32]\n",
      "===== Model Start - 05p, EmbeddingAttention, 32 =====\n",
      "Transformer Embedding imported\n",
      "Will be saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d32_HLAperf.csv\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL0.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.921246783258804\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL1.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9175756773584798\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL2.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9195138644403362\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL3.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9203616653502207\n",
      "\n",
      "\t\t roc: 0.9270313926219875\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL4.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.921405704196995\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL5.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.922049348849702\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL6.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9202091553629723\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL7.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9222654005971143\n",
      "\n",
      "\t\t roc: 0.9285556858189941\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL8.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9188158417979846\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL9.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.921206840674011\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL10.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9176448602922598\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL11.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9200571398633132\n",
      "\n",
      "\t\t roc: 0.9269049240765518\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL12.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9195257903708178\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL13.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9206437293870741\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL14.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9203018469607068\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL15.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9193677309892083\n",
      "\n",
      "\t\t roc: 0.9270812123606689\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL16.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.921158434268647\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL17.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9226336679566919\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL18.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9207919338014502\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL19.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.918931526518442\n",
      "\n",
      "\t\t roc: 0.9276466210433177\n",
      "\t===== Model End - 05p, EmbeddingAttention, 32 =====\n",
      "\t== Stats:\n",
      "\t  auc: 0.9272377546862645\n",
      "\t  auc fpr 0.1: 0.5914845028620077\n",
      "\t  ppv: 0.7139317195948391\n",
      "tn = 1258231, fp = 247223, fn = 46580, tp = 312586\n",
      "y_pred: 0 = 1304811 | 1 = 559809\n",
      "y_true: 0 = 1505454 | 1 = 359166\n",
      "auc=0.9272|sensitivity=0.8703|specificity=0.8358|acc=0.8424|mcc=0.6075\n",
      "precision=0.5584|recall=0.8703|f1=0.6803|aupr=0.7701\n",
      "Saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d32_HLAperf.csv\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['1p', 'EmbeddingAttention', 32]\n",
      "===== Model Start - 1p, EmbeddingAttention, 32 =====\n",
      "Transformer Embedding imported\n",
      "Will be saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d32_HLAperf.csv\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL0.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9455695545184563\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL1.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9407923395449214\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL2.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9385103420354091\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL3.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9397059550278941\n",
      "\n",
      "\t\t roc: 0.9474168393341577\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL4.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9409463330904905\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL5.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9429199697438377\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL6.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9407656386242289\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL7.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.940668441191731\n",
      "\n",
      "\t\t roc: 0.9462611177003362\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL8.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9392946116265861\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL9.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9414634627700209\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL10.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9421022972649234\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL11.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.941522247535277\n",
      "\n",
      "\t\t roc: 0.9463244655034972\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL12.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9385774397251087\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL13.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9410308117914528\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL14.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9423464802618282\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL15.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9414448470995297\n",
      "\n",
      "\t\t roc: 0.945819740962299\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL16.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.939887358096455\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL17.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9403306296529341\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL18.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9417577652340614\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d32_layer1_multihead3_MODEL19.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9415917045734732\n",
      "\n",
      "\t\t roc: 0.9465039669746835\n",
      "\t===== Model End - 1p, EmbeddingAttention, 32 =====\n",
      "\t== Stats:\n",
      "\t  auc: 0.9462051080461877\n",
      "\t  auc fpr 0.1: 0.6810695327749353\n",
      "\t  ppv: 0.7646408624424361\n",
      "tn = 1298452, fp = 207002, fn = 39050, tp = 320116\n",
      "y_pred: 0 = 1337502 | 1 = 527118\n",
      "y_true: 0 = 1505454 | 1 = 359166\n",
      "auc=0.9462|sensitivity=0.8913|specificity=0.8625|acc=0.8680|mcc=0.6601\n",
      "precision=0.6073|recall=0.8913|f1=0.7224|aupr=0.8298\n",
      "Saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d32_HLAperf.csv\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['25p', 'EmbeddingAttention', 32]\n",
      "===== Model Start - 25p, EmbeddingAttention, 32 =====\n",
      "Transformer Embedding imported\n",
      "Will be saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_25p_EmbeddingAttention_d32_HLAperf.csv\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d32_layer1_multihead3_MODEL0.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9747167248070941\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d32_layer1_multihead3_MODEL1.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9739880325187942\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d32_layer1_multihead3_MODEL2.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9750311554757646\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d32_layer1_multihead3_MODEL3.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9744309851239039\n",
      "\n",
      "\t\t roc: 0.9778099092680226\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d32_layer1_multihead3_MODEL4.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.973834846985913\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d32_layer1_multihead3_MODEL5.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9735846406017488\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d32_layer1_multihead3_MODEL6.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9739805972754294\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d32_layer1_multihead3_MODEL7.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9735639746825352\n",
      "\n",
      "\t\t roc: 0.9771723485069571\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d32_layer1_multihead3_MODEL8.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9729713870405721\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d32_layer1_multihead3_MODEL9.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9735154587741062\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d32_layer1_multihead3_MODEL10.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9736294329002636\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d32_layer1_multihead3_MODEL11.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.973768409223555\n",
      "\n",
      "\t\t roc: 0.9770407864188574\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d32_layer1_multihead3_MODEL12.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9743206703866119\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d32_layer1_multihead3_MODEL13.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9741839431209872\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d32_layer1_multihead3_MODEL14.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9733688973374371\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d32_layer1_multihead3_MODEL15.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9734450618109826\n",
      "\n",
      "\t\t roc: 0.9768416648653103\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d32_layer1_multihead3_MODEL16.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9742370063894283\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d32_layer1_multihead3_MODEL17.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9732921086061788\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d32_layer1_multihead3_MODEL18.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9744238978688098\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d32_layer1_multihead3_MODEL19.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9739460957191625\n",
      "\n",
      "\t\t roc: 0.9775469252882305\n",
      "\t===== Model End - 25p, EmbeddingAttention, 32 =====\n",
      "\t== Stats:\n",
      "\t  auc: 0.9772331935022326\n",
      "\t  auc fpr 0.1: 0.8419688843981071\n",
      "\t  ppv: 0.8571663242066343\n",
      "tn = 1385260, fp = 120194, fn = 24992, tp = 334174\n",
      "y_pred: 0 = 1410252 | 1 = 454368\n",
      "y_true: 0 = 1505454 | 1 = 359166\n",
      "auc=0.9772|sensitivity=0.9304|specificity=0.9202|acc=0.9221|mcc=0.7813\n",
      "precision=0.7355|recall=0.9304|f1=0.8215|aupr=0.9237\n",
      "Saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_25p_EmbeddingAttention_d32_HLAperf.csv\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['75p', 'EmbeddingAttention', 32]\n",
      "===== Model Start - 75p, EmbeddingAttention, 32 =====\n",
      "Transformer Embedding imported\n",
      "Will be saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_75p_EmbeddingAttention_d32_HLAperf.csv\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d32_layer1_multihead3_MODEL0.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9778798657416625\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d32_layer1_multihead3_MODEL1.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9784260795218354\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d32_layer1_multihead3_MODEL2.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.978351318601367\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d32_layer1_multihead3_MODEL3.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9780720533798912\n",
      "\n",
      "\t\t roc: 0.9812878092598897\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d32_layer1_multihead3_MODEL4.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9767791209448693\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d32_layer1_multihead3_MODEL5.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9770960246366567\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d32_layer1_multihead3_MODEL6.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9770987961030551\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d32_layer1_multihead3_MODEL7.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9768222217984761\n",
      "\n",
      "\t\t roc: 0.980231342487637\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d32_layer1_multihead3_MODEL8.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9771111596692732\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d32_layer1_multihead3_MODEL9.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9766730951763162\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d32_layer1_multihead3_MODEL10.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9767419710217041\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d32_layer1_multihead3_MODEL11.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9769676357348195\n",
      "\n",
      "\t\t roc: 0.979833628705596\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d32_layer1_multihead3_MODEL12.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9777475707285603\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d32_layer1_multihead3_MODEL13.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9772901549305975\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d32_layer1_multihead3_MODEL14.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9771991032703486\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d32_layer1_multihead3_MODEL15.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9764683910913671\n",
      "\n",
      "\t\t roc: 0.980673600034231\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d32_layer1_multihead3_MODEL16.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9778953210082796\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d32_layer1_multihead3_MODEL17.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.977432507714552\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d32_layer1_multihead3_MODEL18.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9773411799371489\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d32_layer1_multihead3_MODEL19.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9766897834412605\n",
      "\n",
      "\t\t roc: 0.9806217571515825\n",
      "\t===== Model End - 75p, EmbeddingAttention, 32 =====\n",
      "\t== Stats:\n",
      "\t  auc: 0.9805103643532626\n",
      "\t  auc fpr 0.1: 0.8632492430941371\n",
      "\t  ppv: 0.8695450014756408\n",
      "tn = 1394428, fp = 111026, fn = 22343, tp = 336823\n",
      "y_pred: 0 = 1416771 | 1 = 447849\n",
      "y_true: 0 = 1505454 | 1 = 359166\n",
      "auc=0.9805|sensitivity=0.9378|specificity=0.9263|acc=0.9285|mcc=0.7976\n",
      "precision=0.7521|recall=0.9378|f1=0.8347|aupr=0.9351\n",
      "Saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_75p_EmbeddingAttention_d32_HLAperf.csv\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['100p', 'EmbeddingAttention', 32]\n",
      "===== Model Start - 100p, EmbeddingAttention, 32 =====\n",
      "Transformer Embedding imported\n",
      "Will be saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_100p_EmbeddingAttention_d32_HLAperf.csv\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d32_layer1_multihead3_MODEL0.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9790013659570271\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d32_layer1_multihead3_MODEL1.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9779557169816324\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d32_layer1_multihead3_MODEL2.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9782661379847531\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d32_layer1_multihead3_MODEL3.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9782434451878212\n",
      "\n",
      "\t\t roc: 0.9813528314548805\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d32_layer1_multihead3_MODEL4.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.978094049070156\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d32_layer1_multihead3_MODEL5.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.977972601202235\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d32_layer1_multihead3_MODEL6.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9780877906312454\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d32_layer1_multihead3_MODEL7.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9779926266471632\n",
      "\n",
      "\t\t roc: 0.9810011718768927\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d32_layer1_multihead3_MODEL8.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9769191065963951\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d32_layer1_multihead3_MODEL9.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9778894773754615\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d32_layer1_multihead3_MODEL10.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9780979862281265\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d32_layer1_multihead3_MODEL11.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9777546739768317\n",
      "\n",
      "\t\t roc: 0.9804373265034344\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d32_layer1_multihead3_MODEL12.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9776955861191197\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d32_layer1_multihead3_MODEL13.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.978259923814917\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d32_layer1_multihead3_MODEL14.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9782006153209687\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d32_layer1_multihead3_MODEL15.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9775600079192004\n",
      "\n",
      "\t\t roc: 0.9811618469145409\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d32_layer1_multihead3_MODEL16.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.978227467857871\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d32_layer1_multihead3_MODEL17.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9784825876446964\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d32_layer1_multihead3_MODEL18.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.978521257701337\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d32_layer1_multihead3_MODEL19.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9776320128962548\n",
      "\n",
      "\t\t roc: 0.9814254088584549\n",
      "\t===== Model End - 100p, EmbeddingAttention, 32 =====\n",
      "\t== Stats:\n",
      "\t  auc: 0.9810420272133603\n",
      "\t  auc fpr 0.1: 0.8656307879792166\n",
      "\t  ppv: 0.8712044013074735\n",
      "tn = 1405369, fp = 100085, fn = 23912, tp = 335254\n",
      "y_pred: 0 = 1429281 | 1 = 435339\n",
      "y_true: 0 = 1505454 | 1 = 359166\n",
      "auc=0.9810|sensitivity=0.9334|specificity=0.9335|acc=0.9335|mcc=0.8082\n",
      "precision=0.7701|recall=0.9334|f1=0.8439|aupr=0.9364\n",
      "Saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_100p_EmbeddingAttention_d32_HLAperf.csv\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['05p', 'EmbeddingAttention', 64]\n",
      "===== Model Start - 05p, EmbeddingAttention, 64 =====\n",
      "Transformer Embedding imported\n",
      "Will be saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d64_HLAperf.csv\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL0.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.916940915714333\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL1.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9183703477354741\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL2.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9168536244303106\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL3.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9152541307310096\n",
      "\n",
      "\t\t roc: 0.9228660460689493\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL4.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9168696569694982\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL5.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9191058464908677\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL6.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.921120447876716\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL7.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9210911179280897\n",
      "\n",
      "\t\t roc: 0.9256090272728776\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL8.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9155241535434475\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL9.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9183690454865296\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL10.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9212990006288788\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL11.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9187152733842013\n",
      "\n",
      "\t\t roc: 0.9254160637090169\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL12.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9180508921096904\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL13.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9220642905511836\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL14.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9238940485357354\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL15.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9201445330218441\n",
      "\n",
      "\t\t roc: 0.9265964054856641\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL16.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9157922117636076\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL17.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9232264776598353\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL18.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9207903923309697\n",
      "\n",
      "\tOF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL19.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9201743820552345\n",
      "\n",
      "\t\t roc: 0.9257704539049041\n",
      "\t===== Model End - 05p, EmbeddingAttention, 64 =====\n",
      "\t== Stats:\n",
      "\t  auc: 0.9250087739773653\n",
      "\t  auc fpr 0.1: 0.5842367296732087\n",
      "\t  ppv: 0.711874175172483\n",
      "tn = 1236956, fp = 268498, fn = 43437, tp = 315729\n",
      "y_pred: 0 = 1280393 | 1 = 584227\n",
      "y_true: 0 = 1505454 | 1 = 359166\n",
      "auc=0.9250|sensitivity=0.8791|specificity=0.8216|acc=0.8327|mcc=0.5957\n",
      "precision=0.5404|recall=0.8791|f1=0.6693|aupr=0.7616\n",
      "Saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_05p_EmbeddingAttention_125ep_downsample0_d64_HLAperf.csv\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['1p', 'EmbeddingAttention', 64]\n",
      "===== Model Start - 1p, EmbeddingAttention, 64 =====\n",
      "Transformer Embedding imported\n",
      "Will be saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d64_HLAperf.csv\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL0.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9430400789525214\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL1.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9405372627026115\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL2.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9402006571791718\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL3.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9408841912178056\n",
      "\n",
      "\t\t roc: 0.9460114261305324\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL4.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9419711264573831\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL5.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9392606653448388\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL6.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9378190035415144\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL7.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9386617634036691\n",
      "\n",
      "\t\t roc: 0.9440690876010083\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL8.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9410748628370058\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL9.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9385378886113128\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL10.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9385771510677628\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL11.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9335268632388555\n",
      "\n",
      "\t\t roc: 0.9440888601891206\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL12.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9406535479779057\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL13.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.938153759804909\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL14.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.93933023672423\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL15.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9367135080671358\n",
      "\n",
      "\t\t roc: 0.9437362291814937\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL16.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9410469254452842\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL17.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9391647026268185\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL18.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9383399374044052\n",
      "\n",
      "\tOF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d64_layer1_multihead3_MODEL19.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9367922986064031\n",
      "\n",
      "\t\t roc: 0.9435382967267825\n",
      "\t===== Model End - 1p, EmbeddingAttention, 64 =====\n",
      "\t== Stats:\n",
      "\t  auc: 0.9437147474475971\n",
      "\t  auc fpr 0.1: 0.6688487672201163\n",
      "\t  ppv: 0.7600942182723309\n",
      "tn = 1288102, fp = 217352, fn = 39099, tp = 320067\n",
      "y_pred: 0 = 1327201 | 1 = 537419\n",
      "y_true: 0 = 1505454 | 1 = 359166\n",
      "auc=0.9437|sensitivity=0.8911|specificity=0.8556|acc=0.8625|mcc=0.6502\n",
      "precision=0.5956|recall=0.8911|f1=0.7140|aupr=0.8185\n",
      "Saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_1p_EmbeddingAttention_125ep_downsample0_d64_HLAperf.csv\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['25p', 'EmbeddingAttention', 64]\n",
      "===== Model Start - 25p, EmbeddingAttention, 64 =====\n",
      "Transformer Embedding imported\n",
      "Will be saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_25p_EmbeddingAttention_d64_HLAperf.csv\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d64_layer1_multihead3_MODEL0.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9747271412020395\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d64_layer1_multihead3_MODEL1.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9746251993528184\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d64_layer1_multihead3_MODEL2.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9749793505479223\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d64_layer1_multihead3_MODEL3.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9738207866259521\n",
      "\n",
      "\t\t roc: 0.9783787525913601\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d64_layer1_multihead3_MODEL4.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9734265950486793\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d64_layer1_multihead3_MODEL5.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9741435122154496\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d64_layer1_multihead3_MODEL6.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9736969321033547\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d64_layer1_multihead3_MODEL7.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9739673315646452\n",
      "\n",
      "\t\t roc: 0.9780519141149902\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d64_layer1_multihead3_MODEL8.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9736705626392332\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d64_layer1_multihead3_MODEL9.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9733832029708599\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d64_layer1_multihead3_MODEL10.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9737566294647058\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d64_layer1_multihead3_MODEL11.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9739626153450357\n",
      "\n",
      "\t\t roc: 0.9770953251763944\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d64_layer1_multihead3_MODEL12.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9745500200038745\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d64_layer1_multihead3_MODEL13.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9741887376921795\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d64_layer1_multihead3_MODEL14.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9746719444589709\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d64_layer1_multihead3_MODEL15.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9741333100847127\n",
      "\n",
      "\t\t roc: 0.9785179475513948\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d64_layer1_multihead3_MODEL16.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9739568401486947\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d64_layer1_multihead3_MODEL17.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9744835378292971\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d64_layer1_multihead3_MODEL18.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9747817434681132\n",
      "\n",
      "\tOF_TData_pad14_25p_EmbeddingAttention_d64_layer1_multihead3_MODEL19.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9743606730157682\n",
      "\n",
      "\t\t roc: 0.9786703525359348\n",
      "\t===== Model End - 25p, EmbeddingAttention, 64 =====\n",
      "\t== Stats:\n",
      "\t  auc: 0.977075532392858\n",
      "\t  auc fpr 0.1: 0.8418662839739482\n",
      "\t  ppv: 0.8615236408791478\n",
      "tn = 1391580, fp = 113874, fn = 24053, tp = 335113\n",
      "y_pred: 0 = 1415633 | 1 = 448987\n",
      "y_true: 0 = 1505454 | 1 = 359166\n",
      "auc=0.9771|sensitivity=0.9330|specificity=0.9244|acc=0.9260|mcc=0.7908\n",
      "precision=0.7464|recall=0.9330|f1=0.8293|aupr=0.9208\n",
      "Saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_25p_EmbeddingAttention_d64_HLAperf.csv\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['75p', 'EmbeddingAttention', 64]\n",
      "===== Model Start - 75p, EmbeddingAttention, 64 =====\n",
      "Transformer Embedding imported\n",
      "Will be saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_75p_EmbeddingAttention_d64_HLAperf.csv\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d64_layer1_multihead3_MODEL0.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.978002230477893\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d64_layer1_multihead3_MODEL1.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.978226243348862\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d64_layer1_multihead3_MODEL2.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9780258286578556\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d64_layer1_multihead3_MODEL3.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9778448385755141\n",
      "\n",
      "\t\t roc: 0.9811933580187625\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d64_layer1_multihead3_MODEL4.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9771410108477122\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d64_layer1_multihead3_MODEL5.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9773920746788072\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d64_layer1_multihead3_MODEL6.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9767983551556123\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d64_layer1_multihead3_MODEL7.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9776329057049058\n",
      "\n",
      "\t\t roc: 0.980869376811188\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d64_layer1_multihead3_MODEL8.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9769526638347237\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d64_layer1_multihead3_MODEL9.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9770145122158496\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d64_layer1_multihead3_MODEL10.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9773130674178977\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d64_layer1_multihead3_MODEL11.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9767926323311604\n",
      "\n",
      "\t\t roc: 0.9802704643581548\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d64_layer1_multihead3_MODEL12.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9774564271508777\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d64_layer1_multihead3_MODEL13.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9769446340281577\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d64_layer1_multihead3_MODEL14.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9777570664006096\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d64_layer1_multihead3_MODEL15.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9771649101094415\n",
      "\n",
      "\t\t roc: 0.9809897106776639\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d64_layer1_multihead3_MODEL16.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9776865344440508\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d64_layer1_multihead3_MODEL17.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.978048301653631\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d64_layer1_multihead3_MODEL18.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9776713738515226\n",
      "\n",
      "\tOF_TData_pad14_75p_EmbeddingAttention_d64_layer1_multihead3_MODEL19.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9777078301051755\n",
      "\n",
      "\t\t roc: 0.9809683157908398\n",
      "\t===== Model End - 75p, EmbeddingAttention, 64 =====\n",
      "\t== Stats:\n",
      "\t  auc: 0.9808055602077144\n",
      "\t  auc fpr 0.1: 0.8642716084652167\n",
      "\t  ppv: 0.8699876937126565\n",
      "tn = 1400643, fp = 104811, fn = 23474, tp = 335692\n",
      "y_pred: 0 = 1424117 | 1 = 440503\n",
      "y_true: 0 = 1505454 | 1 = 359166\n",
      "auc=0.9808|sensitivity=0.9346|specificity=0.9304|acc=0.9312|mcc=0.8031\n",
      "precision=0.7621|recall=0.9346|f1=0.8396|aupr=0.9359\n",
      "Saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_75p_EmbeddingAttention_d64_HLAperf.csv\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['100p', 'EmbeddingAttention', 64]\n",
      "===== Model Start - 100p, EmbeddingAttention, 64 =====\n",
      "Transformer Embedding imported\n",
      "Will be saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_100p_EmbeddingAttention_d64_HLAperf.csv\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d64_layer1_multihead3_MODEL0.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9786895320863617\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d64_layer1_multihead3_MODEL1.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9789938021453943\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d64_layer1_multihead3_MODEL2.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9786522100781491\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d64_layer1_multihead3_MODEL3.pkl\n",
      "\tTest File ID 0 372896 torch.Size([372896, 14])\n",
      "\t\t\t\t roc: 0.9786097260315543\n",
      "\n",
      "\t\t roc: 0.9817994771565939\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d64_layer1_multihead3_MODEL4.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9784771147512396\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d64_layer1_multihead3_MODEL5.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9783076811861577\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d64_layer1_multihead3_MODEL6.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9786157255986805\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d64_layer1_multihead3_MODEL7.pkl\n",
      "\tTest File ID 1 372782 torch.Size([372782, 14])\n",
      "\t\t\t\t roc: 0.9780388505236592\n",
      "\n",
      "\t\t roc: 0.9816608260891286\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d64_layer1_multihead3_MODEL8.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9780132424811226\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d64_layer1_multihead3_MODEL9.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9775552398619644\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d64_layer1_multihead3_MODEL10.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9779316069720388\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d64_layer1_multihead3_MODEL11.pkl\n",
      "\tTest File ID 2 373210 torch.Size([373210, 14])\n",
      "\t\t\t\t roc: 0.9781556729903844\n",
      "\n",
      "\t\t roc: 0.9808490643798148\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d64_layer1_multihead3_MODEL12.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9784626414159253\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d64_layer1_multihead3_MODEL13.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9785345948756927\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d64_layer1_multihead3_MODEL14.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9784262362165379\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d64_layer1_multihead3_MODEL15.pkl\n",
      "\tTest File ID 3 372504 torch.Size([372504, 14])\n",
      "\t\t\t\t roc: 0.9776877706163731\n",
      "\n",
      "\t\t roc: 0.9813788822500663\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d64_layer1_multihead3_MODEL16.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9780445328461967\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d64_layer1_multihead3_MODEL17.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9791826613128309\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d64_layer1_multihead3_MODEL18.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9788425667163503\n",
      "\n",
      "\tOF_TData_pad14_100p_EmbeddingAttention_d64_layer1_multihead3_MODEL19.pkl\n",
      "\tTest File ID 4 373228 torch.Size([373228, 14])\n",
      "\t\t\t\t roc: 0.9783689760198455\n",
      "\n",
      "\t\t roc: 0.981667173401104\n",
      "\t===== Model End - 100p, EmbeddingAttention, 64 =====\n",
      "\t== Stats:\n",
      "\t  auc: 0.9814548468865427\n",
      "\t  auc fpr 0.1: 0.8683893992253688\n",
      "\t  ppv: 0.8728721538230233\n",
      "tn = 1410586, fp = 94868, fn = 24434, tp = 334732\n",
      "y_pred: 0 = 1435020 | 1 = 429600\n",
      "y_true: 0 = 1505454 | 1 = 359166\n",
      "auc=0.9815|sensitivity=0.9320|specificity=0.9370|acc=0.9360|mcc=0.8138\n",
      "precision=0.7792|recall=0.9320|f1=0.8487|aupr=0.9379\n",
      "Saved: /home/s202357/thesis/transmut/pipeline/procedure/test/perf/OF_TData_pad14_100p_EmbeddingAttention_d64_HLAperf.csv\n"
     ]
    }
   ],
   "source": [
    "for chart_idx_1 in range(len(chart)):\n",
    "\n",
    "    auc_list_temp = []\n",
    "    auc01_list_temp = []\n",
    "    ppv_list_temp = []\n",
    "\n",
    "    for chart_idx_2 in range(len(chart[chart_idx_1])):\n",
    "\n",
    "        model_info = chart[chart_idx_1][chart_idx_2]\n",
    "            \n",
    "        if model_info == \"model_info\":#!= ['100p', 'EmbeddingAttention', 128]:\n",
    "            continue\n",
    "        else:\n",
    "\n",
    "            print('\\n\\n\\n')\n",
    "            print(model_info)\n",
    "            size = model_info[0] \n",
    "            \n",
    "            \n",
    "            if size == '1p':\n",
    "                id_blosum = 'OF_TData_pad14_{}_{}_hlac_pad_downsample0_125ep'\n",
    "                id_emb = 'OF_TData_pad14_{}_{}_125ep_downsample0'\n",
    "            elif size == '05p':\n",
    "                id_blosum = 'OF_TData_pad14_{}_{}_hlac_pad_downsample0_125ep'\n",
    "                id_emb = 'OF_TData_pad14_{}_{}_125ep_downsample0'\n",
    "            else:\n",
    "                id_blosum = 'OF_TData_pad14_{}_{}_hlac_pad'\n",
    "                id_emb = 'OF_TData_pad14_{}_{}'\n",
    "\n",
    "\n",
    "            model_type = model_info[1]\n",
    "            d_model = d_k = d_v = model_info[2]\n",
    "\n",
    "            print('===== Model Start - {}, {}, {} ====='.format(size,model_type,d_model))\n",
    "            if \"Blosum\" in model_type:\n",
    "                model_abbr = 'E'\n",
    "                id_nested = id_blosum.format(size, model_type)  \n",
    "                encoding_ = 'blosum'\n",
    "                print(\"id:\", id_nested)\n",
    "\n",
    "                class EncoderLayer(nn.Module):\n",
    "                    def __init__(self):\n",
    "                        super(EncoderLayer, self).__init__()\n",
    "                        self.enc_self_attn = MultiHeadAttention(d_model, d_k, d_v, n_heads)\n",
    "                        self.pos_ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "                    def forward(self, enc_inputs, enc_self_attn_mask):\n",
    "                        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask) # enc_inputs to same Q,K,V\n",
    "                        enc_outputs = self.pos_ffn(enc_outputs) # enc_outputs: [batch_size, src_len, d_model]\n",
    "                        return enc_outputs, attn\n",
    "\n",
    "\n",
    "                class Encoder(nn.Module):\n",
    "                    def __init__(self):\n",
    "                        super(Encoder, self).__init__()\n",
    "                        self.pos_emb = PositionalEncoding(d_model)\n",
    "                        self.layers = nn.ModuleList([EncoderLayer() for _ in range(n_layers)])\n",
    "\n",
    "                    def forward(self, enc_inputs, pep_to_pad):\n",
    "                        #B# enc_outputs = self.src_emb(enc_inputs) # [batch_size, src_len, d_model]\n",
    "                        enc_outputs = self.pos_emb(enc_inputs.transpose(0, 1)).transpose(0, 1) # [batch_size, src_len, d_model]\n",
    "\n",
    "                        if pep_to_pad != []:\n",
    "                            enc_self_attn_mask = fnc.get_attn_pad_mask(pep_to_pad, pep_to_pad) # [batch_size, src_len, src_len]\n",
    "                        else:\n",
    "                            enc_self_attn_mask = fnc.get_attn_pad_mask_fake(enc_inputs, enc_inputs) # [batch_size, src_len, src_len]\n",
    "\n",
    "                        enc_self_attns = []\n",
    "                        for layer in self.layers:\n",
    "                            enc_outputs, enc_self_attn = layer(enc_outputs, enc_self_attn_mask)\n",
    "                            enc_self_attns.append(enc_self_attn)\n",
    "                        return enc_outputs, enc_self_attns\n",
    "\n",
    "\n",
    "                class DecoderLayer(nn.Module):\n",
    "                    def __init__(self):\n",
    "                        super(DecoderLayer, self).__init__()\n",
    "                        self.dec_self_attn = MultiHeadAttention(d_model, d_k, d_v, n_heads)\n",
    "                        self.pos_ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "                    def forward(self, dec_inputs, dec_self_attn_mask): \n",
    "                        dec_outputs, dec_self_attn = self.dec_self_attn(dec_inputs, dec_inputs, dec_inputs, dec_self_attn_mask)\n",
    "                        dec_outputs = self.pos_ffn(dec_outputs)\n",
    "                        return dec_outputs, dec_self_attn\n",
    "\n",
    "\n",
    "                class Decoder(nn.Module):\n",
    "                    def __init__(self):\n",
    "                        super(Decoder, self).__init__()\n",
    "                        self.use_cuda = use_cuda\n",
    "                        device = torch.device('cuda')\n",
    "                        self.pos_emb = PositionalEncoding(d_model)\n",
    "                        self.layers = nn.ModuleList([DecoderLayer() for _ in range(n_layers)])\n",
    "                        self.tgt_len = tgt_len\n",
    "\n",
    "                    def forward(self, dec_inputs): \n",
    "                        dec_outputs = self.pos_emb(dec_inputs.transpose(0, 1)).transpose(0, 1).to(device) # [batch_size, tgt_len, d_model]\n",
    "                        dec_self_attn_pad_mask = torch.LongTensor(np.zeros((dec_inputs.shape[0], tgt_len, tgt_len))).bool().to(device)\n",
    "\n",
    "                        dec_self_attns = []\n",
    "                        for layer in self.layers:\n",
    "                            dec_outputs, dec_self_attn = layer(dec_outputs, dec_self_attn_pad_mask)\n",
    "                            dec_self_attns.append(dec_self_attn)\n",
    "\n",
    "                        return dec_outputs, dec_self_attns\n",
    "\n",
    "\n",
    "                class Transformer(nn.Module):\n",
    "                    def __init__(self):\n",
    "                        super(Transformer, self).__init__()\n",
    "                        self.use_cuda = use_cuda\n",
    "                        device = torch.device('cuda')\n",
    "                        self.pep_encoder = Encoder().to(device)\n",
    "                        self.hla_encoder = Encoder().to(device)\n",
    "                        self.decoder = Decoder().to(device)\n",
    "                        self.tgt_len = tgt_len\n",
    "                        self.projection = nn.Sequential(\n",
    "                                                        nn.Linear(tgt_len * d_model, 256),\n",
    "                                                        nn.ReLU(True),\n",
    "\n",
    "                                                        nn.BatchNorm1d(256),\n",
    "                                                        nn.Linear(256, 64),\n",
    "                                                        nn.ReLU(True),\n",
    "\n",
    "                                                        nn.Linear(64, 2)\n",
    "                                                        ).to(device)\n",
    "\n",
    "                    def forward(self, pep_inputs, hla_inputs, pep_to_pad):\n",
    "                        pep_enc_outputs, pep_enc_self_attns = self.pep_encoder(pep_inputs, pep_to_pad)\n",
    "                        hla_enc_outputs, hla_enc_self_attns = self.hla_encoder(hla_inputs, [])\n",
    "                        enc_outputs = torch.cat((pep_enc_outputs, hla_enc_outputs), 1)  \n",
    "                        dec_outputs, dec_self_attns = self.decoder(enc_outputs)\n",
    "                        dec_outputs = enc_outputs.view(enc_outputs.shape[0], -1) \n",
    "\n",
    "                        dec_logits = self.projection(dec_outputs) \n",
    "\n",
    "                        return dec_logits.view(-1, dec_logits.size(-1)), pep_enc_self_attns, hla_enc_self_attns\n",
    "\n",
    "                print(\"Transformer Blosum imported\")\n",
    "\n",
    "\n",
    "            if \"Embedding\" in model_type:\n",
    "                model_abbr = 'ED'\n",
    "                id_nested = id_emb.format(size, model_type)\n",
    "                encoding_ = 'embedding'\n",
    "\n",
    "                class EncoderLayer(nn.Module):\n",
    "                    def __init__(self):\n",
    "                        super(EncoderLayer, self).__init__()\n",
    "                        self.enc_self_attn = MultiHeadAttention(d_model, d_k, d_v, n_heads)\n",
    "                        self.pos_ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "                    def forward(self, enc_inputs, enc_self_attn_mask):\n",
    "                        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask) # enc_inputs to same Q,K,V\n",
    "                        enc_outputs = self.pos_ffn(enc_outputs) # enc_outputs: [batch_size, src_len, d_model]\n",
    "                        return enc_outputs, attn\n",
    "\n",
    "\n",
    "                class Encoder(nn.Module):\n",
    "                    def __init__(self):\n",
    "                        super(Encoder, self).__init__()\n",
    "                        self.src_emb = nn.Embedding(vocab_size, d_model)\n",
    "                        self.pos_emb = PositionalEncoding(d_model)\n",
    "                        self.layers = nn.ModuleList([EncoderLayer() for _ in range(n_layers)])\n",
    "\n",
    "                    def forward(self, enc_inputs):\n",
    "                        enc_outputs = self.src_emb(enc_inputs) # [batch_size, src_len, d_model]\n",
    "                        enc_outputs = self.pos_emb(enc_outputs.transpose(0, 1)).transpose(0, 1) # [batch_size, src_len, d_model]\n",
    "                        enc_self_attn_mask = fnc.get_attn_pad_mask(enc_inputs, enc_inputs) # [batch_size, src_len, src_len]\n",
    "\n",
    "                        #print(\"\\n\\nshape enc_inputs-------\")\n",
    "                        #print(\"np.shape(enc_inputs)\", np.shape(enc_inputs))\n",
    "                        #for i in enc_inputs[0]:\n",
    "                        #    print(i)\n",
    "\n",
    "                        enc_self_attns = []\n",
    "                        for layer in self.layers:\n",
    "                            enc_outputs, enc_self_attn = layer(enc_outputs, enc_self_attn_mask)\n",
    "                            enc_self_attns.append(enc_self_attn)\n",
    "                        return enc_outputs, enc_self_attns\n",
    "                print(\"Transformer Embedding imported\")\n",
    "\n",
    "\n",
    "                class DecoderLayer(nn.Module):\n",
    "                    def __init__(self):\n",
    "                        super(DecoderLayer, self).__init__()\n",
    "                        self.dec_self_attn = MultiHeadAttention(d_model, d_k, d_v, n_heads)\n",
    "                        self.pos_ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "                    def forward(self, dec_inputs, dec_self_attn_mask): \n",
    "                        '''\n",
    "                        dec_inputs: [batch_size, tgt_len, d_model]\n",
    "                        enc_outputs: [batch_size, src_len, d_model]\n",
    "                        dec_self_attn_mask: [batch_size, tgt_len, tgt_len]\n",
    "                        '''\n",
    "                        dec_outputs, dec_self_attn = self.dec_self_attn(dec_inputs, dec_inputs, dec_inputs, dec_self_attn_mask)\n",
    "                        dec_outputs = self.pos_ffn(dec_outputs) \n",
    "                        return dec_outputs, dec_self_attn\n",
    "\n",
    "\n",
    "                class Decoder(nn.Module):\n",
    "                    def __init__(self):\n",
    "                        super(Decoder, self).__init__()\n",
    "                        self.use_cuda = use_cuda\n",
    "                        device = torch.device('cuda')\n",
    "                        self.pos_emb = PositionalEncoding(d_model)\n",
    "                        self.layers = nn.ModuleList([DecoderLayer() for _ in range(n_layers)])\n",
    "                        self.tgt_len = tgt_len\n",
    "\n",
    "                    def forward(self, dec_inputs): \n",
    "                        '''\n",
    "                        dec_inputs: [batch_size, tgt_len]\n",
    "                        enc_intpus: [batch_size, src_len]\n",
    "                        enc_outputs: [batsh_size, src_len, d_model]\n",
    "                        '''\n",
    "                        dec_outputs = self.pos_emb(dec_inputs.transpose(0, 1)).transpose(0, 1).to(device) \n",
    "                        dec_self_attn_pad_mask = torch.LongTensor(np.zeros((dec_inputs.shape[0], tgt_len, tgt_len))).bool().to(device)\n",
    "\n",
    "                        dec_self_attns = []\n",
    "                        for layer in self.layers:\n",
    "                            dec_outputs, dec_self_attn = layer(dec_outputs, dec_self_attn_pad_mask)\n",
    "                            dec_self_attns.append(dec_self_attn)\n",
    "\n",
    "                        return dec_outputs, dec_self_attns\n",
    "\n",
    "\n",
    "                class Transformer(nn.Module):\n",
    "                        def __init__(self):\n",
    "                            super(Transformer, self).__init__()\n",
    "                            self.use_cuda = use_cuda\n",
    "                            device = torch.device('cuda')\n",
    "                            self.pep_encoder = Encoder().to(device)\n",
    "                            self.hla_encoder = Encoder().to(device)\n",
    "                            self.decoder = Decoder().to(device)\n",
    "                            self.tgt_len = tgt_len\n",
    "                            self.projection = nn.Sequential(\n",
    "                                                            nn.Linear(tgt_len * d_model, 256),\n",
    "                                                            nn.ReLU(True),\n",
    "\n",
    "                                                            nn.BatchNorm1d(256),\n",
    "                                                            nn.Linear(256, 64),\n",
    "                                                            nn.ReLU(True),\n",
    "\n",
    "                                                            #output layer\n",
    "                                                            nn.Linear(64, 2)\n",
    "                                                            ).to(device)\n",
    "\n",
    "                        def forward(self, pep_inputs, hla_inputs):\n",
    "                            '''\n",
    "                            pep_inputs: [batch_size, pep_len]\n",
    "                            hla_inputs: [batch_size, hla_len]\n",
    "                            '''\n",
    "                            pep_enc_outputs, pep_enc_self_attns = self.pep_encoder(pep_inputs)\n",
    "                            hla_enc_outputs, hla_enc_self_attns = self.hla_encoder(hla_inputs)\n",
    "                            enc_outputs = torch.cat((pep_enc_outputs, hla_enc_outputs), 1) # concat pep & hla embedding\n",
    "\n",
    "                            dec_outputs, dec_self_attns = self.decoder(enc_outputs)\n",
    "                            dec_outputs = dec_outputs.view(dec_outputs.shape[0], -1) # Flatten [batch_size, tgt_len * d_model]\n",
    "                            dec_logits = self.projection(dec_outputs) # dec_logits: [batch_size, tgt_len, tgt_vocab_size]\n",
    "\n",
    "                            return dec_logits.view(-1, dec_logits.size(-1)), pep_enc_self_attns, hla_enc_self_attns, dec_self_attns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            ep_best = 0\n",
    "            fold = 0\n",
    "\n",
    "            test_fold_metrics_list_nested = []\n",
    "\n",
    "            fold_avg_4 = True\n",
    "            type_ = 'test'\n",
    "\n",
    "            df_list = []\n",
    "            time_testing = time.time()\n",
    "\n",
    "            fold_avg_all = [list(range(0,4)), list(range(4,8)), list(range(8,12)), list(range(12,16)), list(range(16,20))] \n",
    "            pred_all = []\n",
    "            target_all = []\n",
    "            enc_attn_list_all = []\n",
    "            enc_hla_attn_list_all = []\n",
    "            \n",
    "            df_name = '/home/s202357/thesis/transmut/pipeline/procedure/test/perf/' + '{}_d{}_HLAperf.csv'.format(id_nested,d_model)\n",
    "            print(\"Will be saved:\", df_name)\n",
    "            for fold_avg, file_num in zip(fold_avg_all,[0,1,2,3,4]):\n",
    "\n",
    "                    pred_fold = []\n",
    "                    target_fold = []\n",
    "                    enc_attn_list_tmp = []\n",
    "                    enc_hla_attn_list_tmp = []\n",
    "\n",
    "                    for f in fold_avg:\n",
    "                        index_order_idx = f\n",
    "                        path_saver = model_folder + fnc.pkl(id_nested, n_layers, n_heads, f, d_model)\n",
    "                        print(\"\\t\"+path_saver.replace(\"/home/s202357/thesis/transmut/pipeline/original/models/\",\"\"))\n",
    "\n",
    "                        test_data, test_pep_inputs, test_hla_inputs, test_labels, test_loader = fnc.data_with_loader_unique(data_dir, \n",
    "                                                                                                                            model_type, \n",
    "                                                                                                                            pep_max_len,\n",
    "                                                                                                                            hla_max_len,\n",
    "                                                                                                                            vocab,\n",
    "                                                                                                                            index_order_idx, \n",
    "                                                                                                                            type_ = type_, \n",
    "                                                                                                                            fold = file_num,  \n",
    "                                                                                                                            batch_size = batch_size)\n",
    "                        model = Transformer().to(device)\n",
    "\n",
    "                        model.load_state_dict(torch.load(path_saver))\n",
    "                        model_test = model.eval()\n",
    "\n",
    "                        if 'Blosum' in model_type:\n",
    "                            ys_res_test, loss_res_test_list, metrics_res_test, y_prob, y_pred_bin, enc_attn_list, enc_hla_attn_list = fnc.eval_step_test_bl(model_test, \n",
    "                                                                                                               model_abbr,\n",
    "                                                                                                               threshold,\n",
    "                                                                                                               test_loader, \n",
    "                                                                                                               fold, \n",
    "                                                                                                               ep_best, \n",
    "                                                                                                               epochs, \n",
    "                                                                                                               use_cuda)\n",
    "\n",
    "                        else:\n",
    "                            ys_res_test, loss_res_test_list, metrics_res_test, y_prob, y_pred_bin, enc_attn_list, enc_hla_attn_list = fnc.eval_step_test(model_test, \n",
    "                                                                                                               model_abbr,\n",
    "                                                                                                               threshold,\n",
    "                                                                                                               test_loader, \n",
    "                                                                                                               fold, \n",
    "                                                                                                               ep_best, \n",
    "                                                                                                               epochs, \n",
    "                                                                                                               use_cuda) # , test_res_attns\n",
    "                        pred_fold.append(y_prob)\n",
    "                        target_fold = [x.item() for x in test_labels]\n",
    "                        print(\"\\t\\t\\t\\t roc:\", roc_auc_score(target_fold, y_prob))\n",
    "                        print(\"\")\n",
    "\n",
    "                        if save_attn:\n",
    "                            enc_attn_list_tmp.append(enc_attn_list)\n",
    "                        if save_attn_hla:\n",
    "                            enc_hla_attn_list_tmp.append(enc_hla_attn_list)\n",
    "\n",
    "                        del test_pep_inputs, test_hla_inputs, test_labels, test_loader, model, ys_res_test, loss_res_test_list, metrics_res_test, y_prob, y_pred_bin\n",
    "                        gc.collect()\n",
    "                        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "                    #print(\"\\t\\tTaking the average:\")   \n",
    "                    # get avg of attn\n",
    "                    if save_attn:\n",
    "                        enc_attn_list_mean = np.mean(enc_attn_list_tmp, axis=0)\n",
    "                        enc_attn_list_all.extend(enc_attn_list_mean)\n",
    "                        del enc_attn_list_tmp, enc_attn_list_mean\n",
    "                        gc.collect()\n",
    "                    if save_attn_hla:\n",
    "                        enc_hla_attn_list_mean = np.mean(enc_hla_attn_list_tmp, axis=0)\n",
    "                        enc_hla_attn_list_all.extend(enc_hla_attn_list_mean)            \n",
    "\n",
    "                    arrays = [np.array(x) for x in pred_fold]\n",
    "                    pred_fold_avg = [np.mean(k) for k in zip(*arrays)]\n",
    "                    pred_all.extend(pred_fold_avg)\n",
    "                    target_all.extend(target_fold)\n",
    "                    print(\"\\t\\t roc:\", roc_auc_score(target_fold, pred_fold_avg))\n",
    "\n",
    "                    test_data['target_'] = target_fold\n",
    "                    test_data['pred_'] = pred_fold_avg\n",
    "                    df_list.append(test_data)\n",
    "\n",
    "\n",
    "            df_pd_nested_test_unique = pd.concat(df_list)\n",
    "\n",
    "            del df_list\n",
    "            del enc_attn_list_tmp\n",
    "            del enc_hla_attn_list_tmp\n",
    "            del enc_attn_list, enc_hla_attn_list\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            df_results = pd.DataFrame(list(zip(target_all, pred_all)), columns= ['target', 'pred'])\n",
    "            print('\\t===== Model End - {}, {}, {} ====='.format(size,model_type,d_model))\n",
    "            print(\"\\t== Stats:\")\n",
    "            auc_ = roc_auc_score(df_results['target'], df_results['pred'])\n",
    "            print(\"\\t  auc:\", auc_)\n",
    "\n",
    "            num_pos = len(df_results[df_results['target']==1])\n",
    "            df_temp_ppv = df_results.sort_values(by=['pred'], ascending=False)[0:num_pos]\n",
    "            num_true_pos = len(df_temp_ppv[df_temp_ppv['target']==1])\n",
    "            ppv = num_true_pos/num_pos\n",
    "            auc_01 = fnc.binary_roc_auc_score(df_results['target'].tolist(), df_results['pred'].tolist(), max_fpr=0.1)\n",
    "            print(\"\\t  auc fpr 0.1:\", auc_01)\n",
    "            print(\"\\t  ppv:\", ppv)\n",
    "\n",
    "            acc_best, i, df_results = fnc.best_treshold(df_results, [0.5])\n",
    "            roc_auc, acc, mcc, f1, sensitivity, specificity, precision, recall, aupr = fnc.performances(df_results['target'], df_results['pred_binary'], df_results['pred'], print_ = True)\n",
    "\n",
    "            auc_list_temp.append(auc_)\n",
    "            auc01_list_temp.append(auc_01)\n",
    "            ppv_list_temp.append(ppv)\n",
    "            \n",
    "            df = df_pd_nested_test_unique.reset_index(drop=True)\n",
    "            HLA_list = list(set(df_pd_nested_test_unique.reset_index(drop=True)['HLA'].tolist()))\n",
    "\n",
    "            HLA_perf = []\n",
    "            for HLA in HLA_list:\n",
    "                temp = df[df['HLA']==HLA]\n",
    "                auc_ = roc_auc_score(temp['target_'], temp['pred_'])\n",
    "\n",
    "                num_pos = len(temp[temp['target_']==1])\n",
    "                df_temp_ppv = temp.sort_values(by=['pred_'], ascending=False)[0:num_pos]\n",
    "                num_true_pos = len(df_temp_ppv[df_temp_ppv['target_']==1])\n",
    "                ppv = num_true_pos/num_pos\n",
    "\n",
    "                auc_01 = fnc.binary_roc_auc_score(temp['target_'].tolist(), temp['pred_'].tolist(), max_fpr=0.1)\n",
    "                HLA_perf.append([HLA, auc_, auc_01, ppv])\n",
    "\n",
    "            HLA_perf_df = pd.DataFrame(HLA_perf, columns = ['HLA', 'AUC', 'AUC01', 'PPV'])  \n",
    "            HLA_perf_df.sort_values(by = ['HLA'])\n",
    "\n",
    "            #df.to_csv('{}_d{}_perf.csv'.format(id_nested,d_model)) \n",
    "            HLA_perf_df.to_csv(df_name) \n",
    "            print(\"Saved:\", df_name)\n",
    "\n",
    "    auc_list.append(auc_list_temp)\n",
    "    auc01_list.append(auc01_list_temp)\n",
    "    ppv_list.append(ppv_list_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>05p</th>\n",
       "      <th>1p</th>\n",
       "      <th>25p</th>\n",
       "      <th>75p</th>\n",
       "      <th>100p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Blosum-20</th>\n",
       "      <td>0.943644</td>\n",
       "      <td>0.956141</td>\n",
       "      <td>0.977631</td>\n",
       "      <td>0.980339</td>\n",
       "      <td>0.980901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-4</th>\n",
       "      <td>0.811233</td>\n",
       "      <td>0.863732</td>\n",
       "      <td>0.962880</td>\n",
       "      <td>0.970418</td>\n",
       "      <td>0.971932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-20</th>\n",
       "      <td>0.934305</td>\n",
       "      <td>0.949801</td>\n",
       "      <td>0.977340</td>\n",
       "      <td>0.980019</td>\n",
       "      <td>0.980775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-32</th>\n",
       "      <td>0.927238</td>\n",
       "      <td>0.946205</td>\n",
       "      <td>0.977233</td>\n",
       "      <td>0.980510</td>\n",
       "      <td>0.981042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-64</th>\n",
       "      <td>0.925009</td>\n",
       "      <td>0.943715</td>\n",
       "      <td>0.977076</td>\n",
       "      <td>0.980806</td>\n",
       "      <td>0.981455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                05p        1p       25p       75p      100p\n",
       "Blosum-20  0.943644  0.956141  0.977631  0.980339  0.980901\n",
       "embd-4     0.811233  0.863732  0.962880  0.970418  0.971932\n",
       "embd-20    0.934305  0.949801  0.977340  0.980019  0.980775\n",
       "embd-32    0.927238  0.946205  0.977233  0.980510  0.981042\n",
       "embd-64    0.925009  0.943715  0.977076  0.980806  0.981455"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>05p</th>\n",
       "      <th>1p</th>\n",
       "      <th>25p</th>\n",
       "      <th>75p</th>\n",
       "      <th>100p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Blosum-20</th>\n",
       "      <td>0.669915</td>\n",
       "      <td>0.731659</td>\n",
       "      <td>0.844002</td>\n",
       "      <td>0.861141</td>\n",
       "      <td>0.864996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-4</th>\n",
       "      <td>0.319561</td>\n",
       "      <td>0.405313</td>\n",
       "      <td>0.766049</td>\n",
       "      <td>0.805648</td>\n",
       "      <td>0.814616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-20</th>\n",
       "      <td>0.629515</td>\n",
       "      <td>0.701896</td>\n",
       "      <td>0.842565</td>\n",
       "      <td>0.860168</td>\n",
       "      <td>0.864119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-32</th>\n",
       "      <td>0.591485</td>\n",
       "      <td>0.681070</td>\n",
       "      <td>0.841969</td>\n",
       "      <td>0.863249</td>\n",
       "      <td>0.865631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-64</th>\n",
       "      <td>0.584237</td>\n",
       "      <td>0.668849</td>\n",
       "      <td>0.841866</td>\n",
       "      <td>0.864272</td>\n",
       "      <td>0.868389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                05p        1p       25p       75p      100p\n",
       "Blosum-20  0.669915  0.731659  0.844002  0.861141  0.864996\n",
       "embd-4     0.319561  0.405313  0.766049  0.805648  0.814616\n",
       "embd-20    0.629515  0.701896  0.842565  0.860168  0.864119\n",
       "embd-32    0.591485  0.681070  0.841969  0.863249  0.865631\n",
       "embd-64    0.584237  0.668849  0.841866  0.864272  0.868389"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>05p</th>\n",
       "      <th>1p</th>\n",
       "      <th>25p</th>\n",
       "      <th>75p</th>\n",
       "      <th>100p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Blosum-20</th>\n",
       "      <td>0.758847</td>\n",
       "      <td>0.792550</td>\n",
       "      <td>0.858074</td>\n",
       "      <td>0.868370</td>\n",
       "      <td>0.870795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-4</th>\n",
       "      <td>0.524242</td>\n",
       "      <td>0.601583</td>\n",
       "      <td>0.812104</td>\n",
       "      <td>0.834862</td>\n",
       "      <td>0.839977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-20</th>\n",
       "      <td>0.735418</td>\n",
       "      <td>0.775474</td>\n",
       "      <td>0.857306</td>\n",
       "      <td>0.867738</td>\n",
       "      <td>0.870283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-32</th>\n",
       "      <td>0.713932</td>\n",
       "      <td>0.764641</td>\n",
       "      <td>0.857166</td>\n",
       "      <td>0.869545</td>\n",
       "      <td>0.871204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-64</th>\n",
       "      <td>0.711874</td>\n",
       "      <td>0.760094</td>\n",
       "      <td>0.861524</td>\n",
       "      <td>0.869988</td>\n",
       "      <td>0.872872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                05p        1p       25p       75p      100p\n",
       "Blosum-20  0.758847  0.792550  0.858074  0.868370  0.870795\n",
       "embd-4     0.524242  0.601583  0.812104  0.834862  0.839977\n",
       "embd-20    0.735418  0.775474  0.857306  0.867738  0.870283\n",
       "embd-32    0.713932  0.764641  0.857166  0.869545  0.871204\n",
       "embd-64    0.711874  0.760094  0.861524  0.869988  0.872872"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def list_to_df(l, column=['05p', '1p', '25p', '75p', '100p'],index =['Blosum-20', 'embd-4', 'embd-20','embd-32','embd-64']):\n",
    "    df = pd.DataFrame(l, columns =column, index=index)\n",
    "    return df\n",
    "\n",
    "display(list_to_df(auc_list))\n",
    "\n",
    "display(list_to_df(auc01_list))\n",
    "\n",
    "display(list_to_df(ppv_list))\n",
    "\n",
    "#Emb 64 is the best with 100% of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>05p</th>\n",
       "      <th>1p</th>\n",
       "      <th>25p</th>\n",
       "      <th>75p</th>\n",
       "      <th>100p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Blosum-20</th>\n",
       "      <td>0.943644</td>\n",
       "      <td>0.956141</td>\n",
       "      <td>0.977631</td>\n",
       "      <td>0.980339</td>\n",
       "      <td>0.980901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-4</th>\n",
       "      <td>0.811233</td>\n",
       "      <td>0.863732</td>\n",
       "      <td>0.962880</td>\n",
       "      <td>0.970418</td>\n",
       "      <td>0.971932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-20</th>\n",
       "      <td>0.934305</td>\n",
       "      <td>0.949801</td>\n",
       "      <td>0.977340</td>\n",
       "      <td>0.980019</td>\n",
       "      <td>0.980775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-32</th>\n",
       "      <td>0.927238</td>\n",
       "      <td>0.946205</td>\n",
       "      <td>0.977233</td>\n",
       "      <td>0.980510</td>\n",
       "      <td>0.981042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-64</th>\n",
       "      <td>0.925009</td>\n",
       "      <td>0.943715</td>\n",
       "      <td>0.977076</td>\n",
       "      <td>0.980806</td>\n",
       "      <td>0.981455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                05p        1p       25p       75p      100p\n",
       "Blosum-20  0.943644  0.956141  0.977631  0.980339  0.980901\n",
       "embd-4     0.811233  0.863732  0.962880  0.970418  0.971932\n",
       "embd-20    0.934305  0.949801  0.977340  0.980019  0.980775\n",
       "embd-32    0.927238  0.946205  0.977233  0.980510  0.981042\n",
       "embd-64    0.925009  0.943715  0.977076  0.980806  0.981455"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>05p</th>\n",
       "      <th>1p</th>\n",
       "      <th>25p</th>\n",
       "      <th>75p</th>\n",
       "      <th>100p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Blosum-20</th>\n",
       "      <td>0.669915</td>\n",
       "      <td>0.731659</td>\n",
       "      <td>0.844002</td>\n",
       "      <td>0.861141</td>\n",
       "      <td>0.864996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-4</th>\n",
       "      <td>0.319561</td>\n",
       "      <td>0.405313</td>\n",
       "      <td>0.766049</td>\n",
       "      <td>0.805648</td>\n",
       "      <td>0.814616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-20</th>\n",
       "      <td>0.629515</td>\n",
       "      <td>0.701896</td>\n",
       "      <td>0.842565</td>\n",
       "      <td>0.860168</td>\n",
       "      <td>0.864119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-32</th>\n",
       "      <td>0.591485</td>\n",
       "      <td>0.681070</td>\n",
       "      <td>0.841969</td>\n",
       "      <td>0.863249</td>\n",
       "      <td>0.865631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-64</th>\n",
       "      <td>0.584237</td>\n",
       "      <td>0.668849</td>\n",
       "      <td>0.841866</td>\n",
       "      <td>0.864272</td>\n",
       "      <td>0.868389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                05p        1p       25p       75p      100p\n",
       "Blosum-20  0.669915  0.731659  0.844002  0.861141  0.864996\n",
       "embd-4     0.319561  0.405313  0.766049  0.805648  0.814616\n",
       "embd-20    0.629515  0.701896  0.842565  0.860168  0.864119\n",
       "embd-32    0.591485  0.681070  0.841969  0.863249  0.865631\n",
       "embd-64    0.584237  0.668849  0.841866  0.864272  0.868389"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>05p</th>\n",
       "      <th>1p</th>\n",
       "      <th>25p</th>\n",
       "      <th>75p</th>\n",
       "      <th>100p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Blosum-20</th>\n",
       "      <td>0.758847</td>\n",
       "      <td>0.792550</td>\n",
       "      <td>0.858074</td>\n",
       "      <td>0.868370</td>\n",
       "      <td>0.870795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-4</th>\n",
       "      <td>0.524242</td>\n",
       "      <td>0.601583</td>\n",
       "      <td>0.812104</td>\n",
       "      <td>0.834862</td>\n",
       "      <td>0.839977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-20</th>\n",
       "      <td>0.735418</td>\n",
       "      <td>0.775474</td>\n",
       "      <td>0.857306</td>\n",
       "      <td>0.867738</td>\n",
       "      <td>0.870283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-32</th>\n",
       "      <td>0.713932</td>\n",
       "      <td>0.764641</td>\n",
       "      <td>0.857166</td>\n",
       "      <td>0.869545</td>\n",
       "      <td>0.871204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-64</th>\n",
       "      <td>0.711874</td>\n",
       "      <td>0.760094</td>\n",
       "      <td>0.861524</td>\n",
       "      <td>0.869988</td>\n",
       "      <td>0.872872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                05p        1p       25p       75p      100p\n",
       "Blosum-20  0.758847  0.792550  0.858074  0.868370  0.870795\n",
       "embd-4     0.524242  0.601583  0.812104  0.834862  0.839977\n",
       "embd-20    0.735418  0.775474  0.857306  0.867738  0.870283\n",
       "embd-32    0.713932  0.764641  0.857166  0.869545  0.871204\n",
       "embd-64    0.711874  0.760094  0.861524  0.869988  0.872872"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def list_to_df(l, column=['05p', '1p', '25p', '75p', '100p'],index =['Blosum-20', 'embd-4', 'embd-20','embd-32','embd-64']):\n",
    "    df = pd.DataFrame(l, columns =column, index=index)\n",
    "    return df\n",
    "\n",
    "display(list_to_df(auc_list))\n",
    "\n",
    "display(list_to_df(auc01_list))\n",
    "\n",
    "display(list_to_df(ppv_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>05p</th>\n",
       "      <th>1p</th>\n",
       "      <th>25p</th>\n",
       "      <th>75p</th>\n",
       "      <th>100p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Blosum-20</th>\n",
       "      <td>0.943644</td>\n",
       "      <td>0.956141</td>\n",
       "      <td>0.977631</td>\n",
       "      <td>0.980339</td>\n",
       "      <td>0.980901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-4</th>\n",
       "      <td>0.811233</td>\n",
       "      <td>0.863732</td>\n",
       "      <td>0.962880</td>\n",
       "      <td>0.970418</td>\n",
       "      <td>0.971932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-20</th>\n",
       "      <td>0.934305</td>\n",
       "      <td>0.949801</td>\n",
       "      <td>0.977340</td>\n",
       "      <td>0.980019</td>\n",
       "      <td>0.980775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-32</th>\n",
       "      <td>0.927238</td>\n",
       "      <td>0.946205</td>\n",
       "      <td>0.977233</td>\n",
       "      <td>0.980510</td>\n",
       "      <td>0.981042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-64</th>\n",
       "      <td>0.925009</td>\n",
       "      <td>0.943715</td>\n",
       "      <td>0.977076</td>\n",
       "      <td>0.980806</td>\n",
       "      <td>0.981455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                05p        1p       25p       75p      100p\n",
       "Blosum-20  0.943644  0.956141  0.977631  0.980339  0.980901\n",
       "embd-4     0.811233  0.863732  0.962880  0.970418  0.971932\n",
       "embd-20    0.934305  0.949801  0.977340  0.980019  0.980775\n",
       "embd-32    0.927238  0.946205  0.977233  0.980510  0.981042\n",
       "embd-64    0.925009  0.943715  0.977076  0.980806  0.981455"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>05p</th>\n",
       "      <th>1p</th>\n",
       "      <th>25p</th>\n",
       "      <th>75p</th>\n",
       "      <th>100p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Blosum-20</th>\n",
       "      <td>0.669915</td>\n",
       "      <td>0.731659</td>\n",
       "      <td>0.844002</td>\n",
       "      <td>0.861141</td>\n",
       "      <td>0.864996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-4</th>\n",
       "      <td>0.319561</td>\n",
       "      <td>0.405313</td>\n",
       "      <td>0.766049</td>\n",
       "      <td>0.805648</td>\n",
       "      <td>0.814616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-20</th>\n",
       "      <td>0.629515</td>\n",
       "      <td>0.701896</td>\n",
       "      <td>0.842565</td>\n",
       "      <td>0.860168</td>\n",
       "      <td>0.864119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-32</th>\n",
       "      <td>0.591485</td>\n",
       "      <td>0.681070</td>\n",
       "      <td>0.841969</td>\n",
       "      <td>0.863249</td>\n",
       "      <td>0.865631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-64</th>\n",
       "      <td>0.584237</td>\n",
       "      <td>0.668849</td>\n",
       "      <td>0.841866</td>\n",
       "      <td>0.864272</td>\n",
       "      <td>0.868389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                05p        1p       25p       75p      100p\n",
       "Blosum-20  0.669915  0.731659  0.844002  0.861141  0.864996\n",
       "embd-4     0.319561  0.405313  0.766049  0.805648  0.814616\n",
       "embd-20    0.629515  0.701896  0.842565  0.860168  0.864119\n",
       "embd-32    0.591485  0.681070  0.841969  0.863249  0.865631\n",
       "embd-64    0.584237  0.668849  0.841866  0.864272  0.868389"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>05p</th>\n",
       "      <th>1p</th>\n",
       "      <th>25p</th>\n",
       "      <th>75p</th>\n",
       "      <th>100p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Blosum-20</th>\n",
       "      <td>0.758847</td>\n",
       "      <td>0.792550</td>\n",
       "      <td>0.858074</td>\n",
       "      <td>0.868370</td>\n",
       "      <td>0.870795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-4</th>\n",
       "      <td>0.524242</td>\n",
       "      <td>0.601583</td>\n",
       "      <td>0.812104</td>\n",
       "      <td>0.834862</td>\n",
       "      <td>0.839977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-20</th>\n",
       "      <td>0.735418</td>\n",
       "      <td>0.775474</td>\n",
       "      <td>0.857306</td>\n",
       "      <td>0.867738</td>\n",
       "      <td>0.870283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-32</th>\n",
       "      <td>0.713932</td>\n",
       "      <td>0.764641</td>\n",
       "      <td>0.857166</td>\n",
       "      <td>0.869545</td>\n",
       "      <td>0.871204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-64</th>\n",
       "      <td>0.711874</td>\n",
       "      <td>0.760094</td>\n",
       "      <td>0.861524</td>\n",
       "      <td>0.869988</td>\n",
       "      <td>0.872872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                05p        1p       25p       75p      100p\n",
       "Blosum-20  0.758847  0.792550  0.858074  0.868370  0.870795\n",
       "embd-4     0.524242  0.601583  0.812104  0.834862  0.839977\n",
       "embd-20    0.735418  0.775474  0.857306  0.867738  0.870283\n",
       "embd-32    0.713932  0.764641  0.857166  0.869545  0.871204\n",
       "embd-64    0.711874  0.760094  0.861524  0.869988  0.872872"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>05p</th>\n",
       "      <th>1p</th>\n",
       "      <th>25p</th>\n",
       "      <th>75p</th>\n",
       "      <th>100p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Blosum-20</th>\n",
       "      <td>0.9436</td>\n",
       "      <td>0.9561</td>\n",
       "      <td>0.9776</td>\n",
       "      <td>0.9803</td>\n",
       "      <td>0.9809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-4</th>\n",
       "      <td>0.8112</td>\n",
       "      <td>0.8637</td>\n",
       "      <td>0.9629</td>\n",
       "      <td>0.9704</td>\n",
       "      <td>0.9719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-20</th>\n",
       "      <td>0.9343</td>\n",
       "      <td>0.9498</td>\n",
       "      <td>0.9773</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.9808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-32</th>\n",
       "      <td>0.9272</td>\n",
       "      <td>0.9462</td>\n",
       "      <td>0.9772</td>\n",
       "      <td>0.9805</td>\n",
       "      <td>0.9810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-64</th>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.9437</td>\n",
       "      <td>0.9771</td>\n",
       "      <td>0.9808</td>\n",
       "      <td>0.9815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              05p      1p     25p     75p    100p\n",
       "Blosum-20  0.9436  0.9561  0.9776  0.9803  0.9809\n",
       "embd-4     0.8112  0.8637  0.9629  0.9704  0.9719\n",
       "embd-20    0.9343  0.9498  0.9773  0.9800  0.9808\n",
       "embd-32    0.9272  0.9462  0.9772  0.9805  0.9810\n",
       "embd-64    0.9250  0.9437  0.9771  0.9808  0.9815"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>05p</th>\n",
       "      <th>1p</th>\n",
       "      <th>25p</th>\n",
       "      <th>75p</th>\n",
       "      <th>100p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Blosum-20</th>\n",
       "      <td>0.6699</td>\n",
       "      <td>0.7317</td>\n",
       "      <td>0.8440</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>0.8650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-4</th>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.4053</td>\n",
       "      <td>0.7660</td>\n",
       "      <td>0.8056</td>\n",
       "      <td>0.8146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-20</th>\n",
       "      <td>0.6295</td>\n",
       "      <td>0.7019</td>\n",
       "      <td>0.8426</td>\n",
       "      <td>0.8602</td>\n",
       "      <td>0.8641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-32</th>\n",
       "      <td>0.5915</td>\n",
       "      <td>0.6811</td>\n",
       "      <td>0.8420</td>\n",
       "      <td>0.8632</td>\n",
       "      <td>0.8656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-64</th>\n",
       "      <td>0.5842</td>\n",
       "      <td>0.6688</td>\n",
       "      <td>0.8419</td>\n",
       "      <td>0.8643</td>\n",
       "      <td>0.8684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              05p      1p     25p     75p    100p\n",
       "Blosum-20  0.6699  0.7317  0.8440  0.8611  0.8650\n",
       "embd-4     0.3196  0.4053  0.7660  0.8056  0.8146\n",
       "embd-20    0.6295  0.7019  0.8426  0.8602  0.8641\n",
       "embd-32    0.5915  0.6811  0.8420  0.8632  0.8656\n",
       "embd-64    0.5842  0.6688  0.8419  0.8643  0.8684"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>05p</th>\n",
       "      <th>1p</th>\n",
       "      <th>25p</th>\n",
       "      <th>75p</th>\n",
       "      <th>100p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Blosum-20</th>\n",
       "      <td>0.7588</td>\n",
       "      <td>0.7925</td>\n",
       "      <td>0.8581</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>0.8708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-4</th>\n",
       "      <td>0.5242</td>\n",
       "      <td>0.6016</td>\n",
       "      <td>0.8121</td>\n",
       "      <td>0.8349</td>\n",
       "      <td>0.8400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-20</th>\n",
       "      <td>0.7354</td>\n",
       "      <td>0.7755</td>\n",
       "      <td>0.8573</td>\n",
       "      <td>0.8677</td>\n",
       "      <td>0.8703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-32</th>\n",
       "      <td>0.7139</td>\n",
       "      <td>0.7646</td>\n",
       "      <td>0.8572</td>\n",
       "      <td>0.8695</td>\n",
       "      <td>0.8712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embd-64</th>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.7601</td>\n",
       "      <td>0.8615</td>\n",
       "      <td>0.8700</td>\n",
       "      <td>0.8729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              05p      1p     25p     75p    100p\n",
       "Blosum-20  0.7588  0.7925  0.8581  0.8684  0.8708\n",
       "embd-4     0.5242  0.6016  0.8121  0.8349  0.8400\n",
       "embd-20    0.7354  0.7755  0.8573  0.8677  0.8703\n",
       "embd-32    0.7139  0.7646  0.8572  0.8695  0.8712\n",
       "embd-64    0.7119  0.7601  0.8615  0.8700  0.8729"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scrape the printed output from May 21\n",
    "auc_list_temp = []\n",
    "auc01_list_temp = []\n",
    "ppv_list_temp = []\n",
    "\n",
    "\n",
    "file1 = open('Attentionbased.txt', 'r')\n",
    "Lines = file1.readlines()\n",
    "\n",
    "# Strips the newline character\n",
    "for line in Lines:\n",
    "    if '\t  auc: ' in line: \n",
    "        auc_list_temp.append( float(line.replace('\t  auc: ', '').replace('\\n', '')))\n",
    "    if '\t  auc fpr 0.1: ' in line:\n",
    "        auc01_list_temp.append( float(line.replace('\t  auc fpr 0.1: ', '').replace('\\n', '')))\n",
    "    if '\t  ppv: ' in line:\n",
    "        ppv_list_temp.append( float(line.replace('\t  ppv: ', '').replace('\\n', '')))\n",
    "        \n",
    "        \n",
    "auc_list = [ auc_list_temp[0:5], auc_list_temp[5:10], auc_list_temp[10:15], auc_list_temp[15:20], auc_list_temp[20:25]]\n",
    "auc01_list = [ auc01_list_temp[0:5], auc01_list_temp[5:10], auc01_list_temp[10:15], auc01_list_temp[15:20], auc01_list_temp[20:25]]\n",
    "ppv_list = [ ppv_list_temp[0:5], ppv_list_temp[5:10], ppv_list_temp[10:15], ppv_list_temp[15:20], ppv_list_temp[20:25]]\n",
    "\n",
    "auc_list_temp = [ round(x, 4) for x in auc_list_temp ]\n",
    "auc01_list_temp = [ round(x, 4) for x in auc01_list_temp ]\n",
    "ppv_list_temp = [ round(x, 4) for x in ppv_list_temp ]\n",
    "\n",
    "auc_list_r = [ auc_list_temp[0:5], auc_list_temp[5:10], auc_list_temp[10:15], auc_list_temp[15:20], auc_list_temp[20:25]]\n",
    "auc01_list_r = [ auc01_list_temp[0:5], auc01_list_temp[5:10], auc01_list_temp[10:15], auc01_list_temp[15:20], auc01_list_temp[20:25]]\n",
    "ppv_list_r = [ ppv_list_temp[0:5], ppv_list_temp[5:10], ppv_list_temp[10:15], ppv_list_temp[15:20], ppv_list_temp[20:25]]\n",
    "\n",
    "\n",
    "display(list_to_df(auc_list))\n",
    "\n",
    "display(list_to_df(auc01_list))\n",
    "\n",
    "display(list_to_df(ppv_list))\n",
    "    \n",
    "print(\"---------------------\")    \n",
    "\n",
    "display(list_to_df(auc_list_r))\n",
    "\n",
    "display(list_to_df(auc01_list_r))\n",
    "\n",
    "display(list_to_df(ppv_list_r))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peptide len spec perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bl['Type']= 'BLOSUM'\n",
    "\n",
    "df_bl_per_len = []\n",
    "\n",
    "for len_ in [8,9,10,11,12,13,14]:\n",
    "    temp = df_bl[df_bl['length']==len_]\n",
    "    HLA_list = list(set(df_pd_nested_test_unique.reset_index(drop=True)['HLA'].tolist()))\n",
    "    auc_ = roc_auc_score(temp['target_'], temp['pred_'])\n",
    "\n",
    "    num_pos = len(temp[temp['target_']==1])\n",
    "    df_temp_ppv = temp.sort_values(by=['pred_'], ascending=False)[0:num_pos]\n",
    "    num_true_pos = len(df_temp_ppv[df_temp_ppv['target_']==1])\n",
    "    ppv = num_true_pos/num_pos\n",
    "\n",
    "    auc_01 = fnc.binary_roc_auc_score(temp['target_'].tolist(), temp['pred_'].tolist(), max_fpr=0.1)\n",
    "    df_bl_per_len.append([len_, auc_, auc_01, ppv, 'BLOSUM'])\n",
    "\n",
    "df_bl_len = pd.DataFrame(df_bl_per_len, columns=['Peptide Length', 'AUC', 'AUC01', 'PPV', 'Method'])\n",
    "\n",
    "df_per_len = []\n",
    "\n",
    "for len_ in [8,9,10,11,12,13,14]:\n",
    "    temp = df[df_bl['length']==len_]\n",
    "    HLA_list = list(set(df_pd_nested_test_unique.reset_index(drop=True)['HLA'].tolist()))\n",
    "    auc_ = roc_auc_score(temp['target_'], temp['pred_'])\n",
    "\n",
    "    num_pos = len(temp[temp['target_']==1])\n",
    "    df_temp_ppv = temp.sort_values(by=['pred_'], ascending=False)[0:num_pos]\n",
    "    num_true_pos = len(df_temp_ppv[df_temp_ppv['target_']==1])\n",
    "    ppv = num_true_pos/num_pos\n",
    "\n",
    "    auc_01 = fnc.binary_roc_auc_score(temp['target_'].tolist(), temp['pred_'].tolist(), max_fpr=0.1)\n",
    "    df_per_len.append([len_, auc_, auc_01, ppv, 'LE'])\n",
    "\n",
    "df_len = pd.DataFrame(df_per_len, columns=['Peptide Length', 'AUC', 'AUC01', 'PPV', 'Method'])\n",
    "\n",
    "concat = pd.concat([df_bl_len, df_len], axis=0)\n",
    "concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for metric in ['AUC01', 'PPV']:\n",
    "    sn.set(rc = {'figure.figsize':(7,5)})\n",
    "\n",
    "    sn.set(style='white')\n",
    "\n",
    "    sn.barplot(x='Peptide Length', y=metric, hue='Method', data=concat, palette = 'GnBu')\n",
    "    \n",
    "\n",
    "    for ax in plt.gcf().axes:\n",
    "        l = ax.get_xlabel()\n",
    "        ax.set_xlabel(l, fontsize=25)\n",
    "\n",
    "    for ax in plt.gcf().axes:\n",
    "        l = ax.get_ylabel()\n",
    "        ax.set_ylabel(l, fontsize=25)\n",
    "\n",
    "    sn.set(font_scale=2.1)\n",
    "\n",
    "    sn.despine(offset=10, trim=True)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (transformers)",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
